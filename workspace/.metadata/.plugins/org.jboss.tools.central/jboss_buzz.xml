<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Announcing: Thorntail 2.2 General Availability</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/3iULLfSedp0/" /><category term="Announcement" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="microprofile" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="Modern App Dev" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Application Runtimes" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><category term="RHOAR" scheme="searchisko:content:tags" /><category term="thorntail" scheme="searchisko:content:tags" /><category term="wildfly swarm" scheme="searchisko:content:tags" /><author><name>James Falkner</name></author><id>searchisko:content:id:jbossorg_blog-announcing_thorntail_2_2_general_availability</id><updated>2018-10-17T19:25:51Z</updated><published>2018-10-17T19:25:51Z</published><content type="html">&lt;div style="float: right;"&gt;&lt;/div&gt; &lt;h2&gt;Summary&lt;/h2&gt; &lt;p&gt;Today Red Hat is making Thorntail 2.2 generally available to Red Hat customers through a subscription to &lt;a href="http://developers.redhat.com/rhoar"&gt;Red Hat OpenShift Application Runtimes&lt;/a&gt; (RHOAR). RHOAR provides application developers with a variety of application runtimes running on the &lt;a href="https://www.openshift.com/"&gt;OpenShift Container Platform&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Thorntail is the &lt;a href="https://www.infoq.com/news/2018/05/wildfly-thorntail"&gt;new name&lt;/a&gt; for WildFly Swarm, and bundles everything you need to develop and run &lt;a href="https://developers.redhat.com/blog/2018/08/23/eclipse-microprofile-and-red-hat-update-thorntail-and-smallrye/"&gt;Thorntail&lt;/a&gt; and &lt;a href="https://microprofile.io/"&gt;MicroProfile&lt;/a&gt; applications by packaging server runtime libraries with your application code and running it with &lt;code&gt;java -jar&lt;/code&gt;. It speeds up the transition from monoliths to microservices and takes advantage of your existing industry standard Java EE technology experience.&lt;/p&gt; &lt;p&gt;&lt;span id="more-528527"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;What’s in the box?&lt;/h2&gt; &lt;p&gt;This release is an incremental release from WildFly Swarm 7.1, and adds support for MicroProfile 1.3, a feature-rich collection of APIs for developing enterprise &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt;. Beyond the core Java EE technologies like JAX-RS, CDI, and JSON-P, MicroProfile 1.3 includes:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://microprofile.io/project/eclipse/microprofile-config"&gt;&lt;strong&gt;Config 1.2&lt;/strong&gt;&lt;/a&gt;: Externalizes configuration, separating business logic from service configuration. Service configurations developed with Thorntail 2.2 can be can read from &lt;a href="https://docs.openshift.com/container-platform/3.11/dev_guide/configmaps.html"&gt;OpenShift ConfigMaps&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;a href="https://microprofile.io/project/eclipse/microprofile-fault-tolerance"&gt;&lt;strong&gt;Fault Tolerance 1.0&lt;/strong&gt;&lt;/a&gt;: Implements a collection of programming patterns like Bulkheads, Timeouts, Circuit Breakers, and Fallbacks to monitor and gracefully react to potential failure conditions. Utilizing these patterns can eliminate the potential for cascading failures in a microservices architecture.&lt;/li&gt; &lt;li&gt;&lt;a href="https://microprofile.io/project/eclipse/microprofile-metrics"&gt;&lt;strong&gt;Metrics 1.1&lt;/strong&gt;&lt;/a&gt;: Exposes a collection of common runtime metrics and custom application-defined metrics using constructs like Gauges, Counters, and Meters. Services developed with Thorntail 2.2 can be exposed to Prometheus monitoring on OpenShift.&lt;/li&gt; &lt;li&gt;&lt;a href="https://microprofile.io/project/eclipse/microprofile-health"&gt;&lt;strong&gt;Health Check 1.0&lt;/strong&gt;&lt;/a&gt;: Standard endpoint that exposes a custom-developed service’s health to the underlying platform. When running on OpenShift, health check probes can monitor this endpoint and restart the containers running an unhealthy service.&lt;/li&gt; &lt;li&gt;&lt;a href="https://microprofile.io/project/eclipse/microprofile-opentracing"&gt;&lt;strong&gt;OpenTracing 1.0&lt;/strong&gt;&lt;/a&gt;: Enables tracing the flow of a request as it traverses multiple services within a microservices architecture. When Thorntail is used with Jaeger (a distributed tracing service), organizations can quickly track down performance bottlenecks.&lt;/li&gt; &lt;li&gt;&lt;a href="https://microprofile.io/project/eclipse/microprofile-open-api"&gt;&lt;strong&gt;Open API 1.0&lt;/strong&gt;&lt;/a&gt;: A Java implementation of the Open API specification that exposes machine-readable format of custom-developed RESTful endpoints.&lt;/li&gt; &lt;li&gt;&lt;a href="https://microprofile.io/project/eclipse/microprofile-rest-client"&gt;&lt;strong&gt;Rest Client 1.0&lt;/strong&gt;&lt;/a&gt;: A type-safe API for invoking RESTful services.&lt;/li&gt; &lt;li&gt;&lt;a href="https://microprofile.io/project/eclipse/microprofile-jwt-auth"&gt;&lt;strong&gt;JWT RBAC 1.0&lt;/strong&gt;&lt;/a&gt;: Using OpenID Connect (OIDC)-based JSON Web Tokens (JWT) for role-based access control of microservices endpoints.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Thorntail also includes a number of features that make it easy to deploy and manage Thorntail projects, such as integrating data sources, support for &lt;a href="https://www.keycloak.org/"&gt;Keycloak&lt;/a&gt; and &lt;a href="https://access.redhat.com/products/red-hat-single-sign-on"&gt;Red Hat SSO&lt;/a&gt;, and more. Consult the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_runtimes/1/html/red_hat_openshift_application_runtimes_release_notes/"&gt;release notes&lt;/a&gt; for a complete list.&lt;/p&gt; &lt;h2&gt;Besides the name, what else has changed?&lt;/h2&gt; &lt;p&gt;With the exception of the build configuration file (&lt;code&gt;pom.xml&lt;/code&gt;) and log output (more below), Thorntail is API-compatible with WildFly Swarm. The build configuration file will need to be updated with name of Thorntail artifacts:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;org.wildfly.swarm&lt;/code&gt; references will need to be changed to &lt;code&gt;io.thorntail&lt;/code&gt;&lt;/li&gt; &lt;li&gt;If you&amp;#8217;re using the WildFly Swarm &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_runtimes/1/html-single/thorntail_runtime_guide/#using-thorntail-maven-plugin_wf-swarm"&gt;Maven Plugin&lt;/a&gt;, you&amp;#8217;ll need to update the Maven &lt;code&gt;artifactId&lt;/code&gt; to &lt;code&gt;thorntail-maven-plugin&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This can be automated using a simple Maven command (run from your project&amp;#8217;s base directory):&lt;/p&gt; &lt;pre&gt;mvn io.thorntail:thorntail-maven-plugin:2.2.0.Final-redhat-00021:migrate-from-wildfly-swarm&lt;/pre&gt; &lt;p&gt;Be aware that the suffix used in the name of the generated &lt;em&gt;uberjar&lt;/em&gt; also changes to &lt;code&gt;-thorntail.jar&lt;/code&gt;. If you have CI/CD logic that depends on this suffix, you&amp;#8217;ll need to update to take this into account.&lt;/p&gt; &lt;p&gt;A few other notes:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Because Thorntail is considered the “next dot release” of WildFly Swarm, there are new features available, most notably support for &lt;a href="https://github.com/eclipse/microprofile-bom/releases/tag/1.3"&gt;MicroProfile 1.3&lt;/a&gt; (see above)&lt;/li&gt; &lt;li&gt;With the rename to Thorntail, the version of Thorntail available with RHOAR will be identical to the upstream project version releases. This will make it easier for you to map versions of Thorntail to an upstream release.&lt;/li&gt; &lt;li&gt;Log message codes have changed from &lt;code&gt;WFSnnnnn&lt;/code&gt; or &lt;code&gt;WFSWARMnnnn&lt;/code&gt; to &lt;code&gt;THORNnnnnn&lt;/code&gt; or &lt;code&gt;TTnnnnn&lt;/code&gt;. Any monitoring of error codes will need to be updated.&lt;/li&gt; &lt;li&gt;And finally, Thorntail has a new logo you can see at the top of this post!&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Launch into OpenShift&lt;/h2&gt; &lt;div id="attachment_528577" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="http://developers.redhat.com/launch"&gt;&lt;img class=" size-large wp-image-528577 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-17-at-10.51.04-AM-1024x473.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-17-at-10.51.04-AM-1024x473.png" alt="Thorntail featured in Launcher" width="640" height="296" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-17-at-10.51.04-AM-1024x473.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-17-at-10.51.04-AM-300x139.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-17-at-10.51.04-AM-768x355.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-17-at-10.51.04-AM.png 1416w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p class="wp-caption-text"&gt;Thorntail featured in Launcher&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Using &lt;a href="https://developers.redhat.com/launch"&gt;developers.redhat.com/launch&lt;/a&gt; you can immediately create and deploy a Thorntail application directly to &lt;a href="http://openshift.com/"&gt;OpenShift Online&lt;/a&gt; or to your own local OpenShift cluster. It provides a hassle-free way of creating example applications, called boosters, as well as an easy way to build and deploy those boosters to OpenShift.&lt;/p&gt; &lt;p&gt;Boosters are available to showcase how developers can use Thorntail to build fundamental building blocks of cloud-native applications and services, such as creating secured RESTful APIs, implementing health checks, externalizing configuration, or integrating with the OpenShift Service Mesh based on the &lt;a href="https://developers.redhat.com/topics/service-mesh/"&gt;Istio&lt;/a&gt; project.&lt;/p&gt; &lt;h2&gt;Test Driving a sample app&lt;/h2&gt; &lt;p&gt;Thorntail is a Java framework, and as such it can be run using &lt;a href="https://developers.redhat.com/products/openjdk/overview/"&gt;OpenJDK&lt;/a&gt;. Let&amp;#8217;s test drive one of the Thorntail boosters on OpenShift (here I am using the &lt;a href="https://developers.redhat.com/products/cdk/overview/"&gt;Red Hat CDK&lt;/a&gt;, but any OpenShift cluster will do). The following is one set of commands you could use to pull the OpenJDK image to your local system for use with Thorntail:&lt;/p&gt; &lt;pre&gt;oc new-project thorntail oc import-image java:8 --from=registry.access.redhat.com/redhat-openjdk-18/openjdk18-openshift --confirm&lt;/pre&gt; &lt;p&gt;Then, the following commands could be used to build and deploy the Thorntail application to Red Hat OpenShift:&lt;/p&gt; &lt;pre&gt;oc new-app --name rest-example 'java:8~https://github.com/thorntail-examples/rest-http-redhat#2.2.0-redhat-1' oc expose svc/rest-example&lt;/pre&gt; &lt;p&gt;You can watch the build take place:&lt;/p&gt; &lt;pre&gt;oc logs -f bc/rest-example&lt;/pre&gt; &lt;p&gt;Once the build completes, wait for the deployment to finish:&lt;/p&gt; &lt;pre&gt;oc rollout status -w dc/rest-example&lt;/pre&gt; &lt;p&gt;And then access the sample app&amp;#8217;s UI:&lt;/p&gt; &lt;pre&gt;open http://$(oc get route rest-example -o jsonpath='{.spec.host}{"\n"}')&lt;/pre&gt; &lt;p&gt;Red Hat Customers using the OpenJDK distribution with Thorntail will be able to keep current with the latest updates, security advisories, knowing when and why containers are updated, and remaining up-to-date on the latest available tagged image.&lt;/p&gt; &lt;h2&gt;Documentation&lt;/h2&gt; &lt;p&gt;The RHOAR team has been continuously adding and improving on the official documentation for Thorntail. This includes updates in the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_runtimes/1/html/red_hat_openshift_application_runtimes_release_notes/"&gt;Release Notes&lt;/a&gt;, &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_runtimes/1/html/getting_started_with_red_hat_openshift_application_runtimes/"&gt;Getting Started Guide,&lt;/a&gt; and the new &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_runtimes/1/html/thorntail_runtime_guide/"&gt;Thorntail Runtime Guide&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Developer Interactive Learning Scenarios&lt;/h2&gt; &lt;p&gt;These &lt;a href="https://learn.openshift.com/middleware/rhoar-getting-started-thorntail/"&gt;self-paced scenarios&lt;/a&gt; provide you with a pre-configured OpenShift instance, accessible from your browser without any downloads or configuration. Use it to &lt;a href="https://learn.openshift.com/middleware/rhoar-getting-started-thorntail/"&gt;experiment with Thorntail&lt;/a&gt;, or learn about other technologies within RHOAR and see how its helps solve real-world problems.&lt;/p&gt; &lt;div id="attachment_528797" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://learn.openshift.com/middleware/rhoar-getting-started-thorntail/"&gt;&lt;img class=" size-large wp-image-528797 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-17-at-2.25.40-PM-1024x732.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-17-at-2.25.40-PM-1024x732.png" alt="Interactive Learning Scenario for Thorntail" width="640" height="458" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-17-at-2.25.40-PM-1024x732.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-17-at-2.25.40-PM-300x215.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-17-at-2.25.40-PM-768x549.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-17-at-2.25.40-PM.png 1271w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p class="wp-caption-text"&gt;Interactive Learning Scenario for Thorntail&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Getting Support&lt;/h2&gt; &lt;p&gt;Support for Thorntail is available to Red Hat customers through a subscription to Red Hat OpenShift Application Runtimes. Contact your local Red Hat representative or &lt;a href="https://www.redhat.com/en/about/contact/sales"&gt;Red Hat Sales&lt;/a&gt; for details on how you can enjoy world-class support offered from Red Hat and its worldwide partner network.&lt;/p&gt; &lt;p&gt;Moving forward, customers can expect support for Thorntail and other RHOAR runtimes according to the &lt;a href="https://access.redhat.com/support/policy/updates/jboss_notes/"&gt;Red Hat Product Update and Support Lifecycle&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;What’s Next?&lt;/h2&gt; &lt;p&gt;The Thorntail team is continually taking &lt;a href="https://issues.jboss.org/projects/THORN/issues?filter=allopenissues"&gt;feedback&lt;/a&gt; from customers and the wider community of open source developers, as well as tracking the &lt;a href="https://thorntail.io/downloads/"&gt;upstream Thorntail releases.&lt;/a&gt; They are working to make updates to the RHOAR runtimes based on that feedback, as well as considering support for additional modules from Red Hat and the very large Java community. The Thorntail community is also continuing to track the evolution of and contribute to &lt;a href="https://developers.redhat.com/blog/2018/04/24/jakarta-ee-is-officially-out/"&gt;Jakarta EE&lt;/a&gt; as well as the advances in the &lt;a href="https://microprofile.io"&gt;MicroProfile project&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Kudos!&lt;/h2&gt; &lt;p&gt;This release was produced by Red Hat’s RHOAR product team, and involved many hours of development, testing, writing documentation, testing some more, and working with the wider Red Hat community of customers, partners, and Thorntail developers to incorporate contributions, both big and small. We are glad you have chosen to use it, and hope that it meets or exceeds your expectations!&lt;/p&gt; &lt;h2&gt;More Resources&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="http://developers.redhat.com/rhoar"&gt;Red Hat OpenShift Application Runtimes Developer home page&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/08/23/eclipse-microprofile-and-red-hat-update-thorntail-and-smallrye/"&gt;Eclipse MicroProfile and Red Hat Update: Thorntail and SmallRye&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://thorntail.io/archive/"&gt;Thorntail Blog&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_runtimes/1/html/thorntail_runtime_guide/"&gt;Thorntail Runtime Guide&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://groups.google.com/forum/#!forum/thorntail"&gt;Thorntail Discussion Group&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://twitter.com/thorntail_io"&gt;Thorntail on Twitter&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="http://webchat.freenode.net/?channels=thorntail"&gt;Thorntail on IRC&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://issues.jboss.org/projects/THORN/issues?filter=allopenissues"&gt;Thorntail Issue Tracker&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/05/07/microprofile-status-version-1-3/"&gt;MicroProfile Status in version 1.3&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://microprofile.io"&gt;MicroProfile&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fannouncing-thorntail-2-2-general-availability%2F&amp;#38;linkname=Announcing%3A%20Thorntail%202.2%20General%20Availability" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fannouncing-thorntail-2-2-general-availability%2F&amp;#38;linkname=Announcing%3A%20Thorntail%202.2%20General%20Availability" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fannouncing-thorntail-2-2-general-availability%2F&amp;#38;linkname=Announcing%3A%20Thorntail%202.2%20General%20Availability" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fannouncing-thorntail-2-2-general-availability%2F&amp;#38;linkname=Announcing%3A%20Thorntail%202.2%20General%20Availability" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fannouncing-thorntail-2-2-general-availability%2F&amp;#38;linkname=Announcing%3A%20Thorntail%202.2%20General%20Availability" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fannouncing-thorntail-2-2-general-availability%2F&amp;#38;linkname=Announcing%3A%20Thorntail%202.2%20General%20Availability" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fannouncing-thorntail-2-2-general-availability%2F&amp;#38;linkname=Announcing%3A%20Thorntail%202.2%20General%20Availability" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fannouncing-thorntail-2-2-general-availability%2F&amp;#38;linkname=Announcing%3A%20Thorntail%202.2%20General%20Availability" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fannouncing-thorntail-2-2-general-availability%2F&amp;#38;title=Announcing%3A%20Thorntail%202.2%20General%20Availability" data-a2a-url="https://developers.redhat.com/blog/2018/10/17/announcing-thorntail-2-2-general-availability/" data-a2a-title="Announcing: Thorntail 2.2 General Availability"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/17/announcing-thorntail-2-2-general-availability/"&gt;Announcing: Thorntail 2.2 General Availability&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/3iULLfSedp0" height="1" width="1" alt=""/&gt;</content><summary>Summary Today Red Hat is making Thorntail 2.2 generally available to Red Hat customers through a subscription to Red Hat OpenShift Application Runtimes (RHOAR). RHOAR provides application developers with a variety of application runtimes running on the OpenShift Container Platform. Thorntail is the new name for WildFly Swarm, and bundles everything you need to develop and run Thorntail and MicroPr...</summary><dc:creator>James Falkner</dc:creator><dc:date>2018-10-17T19:25:51Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/10/17/announcing-thorntail-2-2-general-availability/</feedburner:origLink></entry><entry><title>Deploying MicroProfile apps on Microsoft Azure using the Azure Open Service Broker</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/rQnYQZWQQWE/" /><category term="azure" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="microprofile" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="Modern App Dev" scheme="searchisko:content:tags" /><category term="mongodb" scheme="searchisko:content:tags" /><category term="Open Service Broker" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Application Runtimes" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><category term="thorntail" scheme="searchisko:content:tags" /><category term="wildfly swarm" scheme="searchisko:content:tags" /><author><name>James Falkner</name></author><id>searchisko:content:id:jbossorg_blog-deploying_microprofile_apps_on_microsoft_azure_using_the_azure_open_service_broker</id><updated>2018-10-17T18:00:28Z</updated><published>2018-10-17T18:00:28Z</published><content type="html">&lt;p&gt;At the recently concluded &lt;a href="https://www.redhat.com/en/events/red-hat-microsoft-ignite-2018"&gt;Microsoft Ignite 2018&lt;/a&gt; conference in Orlando, I had the honor of presenting to a crowd of Java developers and Azure professionals eager to learn how to put their Java skills to work building next-gen apps on Azure. Of course, that meant showcasing the technology coming out of the popular &lt;a href="https://microprofile.io"&gt;MicroProfile&lt;/a&gt; community, in which Red Hat plays a big part (and makes a fully supported, productized MicroProfile implementation through &lt;a href="https://thorntail.io"&gt;Thorntail&lt;/a&gt;, part of &lt;a href="https://developers.redhat.com/rhoar"&gt;Red Hat OpenShift Application Runtimes&lt;/a&gt;).&lt;/p&gt; &lt;p&gt;We did a demo too, which is the main topic of this blog post, showing how easy it is to link your Java MicroProfile apps to Azure services through the &lt;a href="https://github.com/Azure/open-service-broker-azure"&gt;Open Service Broker for Azure&lt;/a&gt; (the open source, &lt;a href="https://www.openservicebrokerapi.org/" rel="nofollow"&gt;Open Service Broker&lt;/a&gt;-compatible API server that provisions managed services in the Microsoft Azure public cloud) and &lt;a href="https://github.com/openshift/service-catalog"&gt;OpenShift&amp;#8217;s Service Catalog&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Here&amp;#8217;s how to reproduce the demo.&lt;/p&gt; &lt;p&gt;&lt;span id="more-524367"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;The Demo&lt;/h2&gt; &lt;p&gt;I was joined on stage by &lt;a href="https://twitter.com/cesar_saavedr"&gt;Cesar Saavedra&lt;/a&gt; from Red Hat (Technical Marketing for MicroProfile and Red Hat) and &lt;a href="http://twitter.com/bbenz"&gt;Brian Benz&lt;/a&gt; (Dev Advocate for Microsoft), and we introduced the MicroProfile origins, goals, community makeup, roadmap, and a few other items.&lt;/p&gt; &lt;p&gt;Then it was time for the demo. You can &lt;a href="https://www.youtube.com/watch?v=-nAjEsBjkLA"&gt;watch the video of the session&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/-nAjEsBjkLA?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;p&gt;The demo application should look familiar to you:&lt;/p&gt; &lt;div id="attachment_524407" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-09-20-at-2.07.12-PM.png"&gt;&lt;img class="wp-image-524407 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-09-20-at-2.07.12-PM-1024x871.png" alt="MicroSweeper screenshot" width="640" height="544" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-09-20-at-2.07.12-PM-1024x871.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-09-20-at-2.07.12-PM-300x255.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-09-20-at-2.07.12-PM-768x653.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-09-20-at-2.07.12-PM.png 1502w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p class="wp-caption-text"&gt;MicroSweeper screenshot&lt;/p&gt;&lt;/div&gt; &lt;p&gt;This game is the classic &lt;a href="https://en.wikipedia.org/wiki/Microsoft_Minesweeper"&gt;Minesweeper&lt;/a&gt;, first introduced to the Windows world in 1992 with Windows 3.1, and much appreciated by the various graying heads in the audience (shout out to &lt;a href="http://www.nickarocho.com/"&gt;Nick Arocho&lt;/a&gt; for his awesome JavaScript implementation of the UI!).&lt;/p&gt; &lt;p&gt;To this game, I added a simple scoreboard backed by a database, and it was our job in the demo to hook this application up to Azure&amp;#8217;s &lt;a href="https://azure.microsoft.com/en-us/services/cosmos-db/"&gt;Cosmos DB&lt;/a&gt; service using the &lt;a href="https://github.com/eclipse/microprofile-config"&gt;MicroProfile Config API&lt;/a&gt;, as well integrate with OpenShift&amp;#8217;s &lt;a href="https://docs.okd.io/latest/dev_guide/application_health.html"&gt;health probes&lt;/a&gt; using the simple &lt;a href="https://github.com/eclipse/microprofile-health"&gt;MicroProfile Health APIs&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The section below describes how to reproduce the demo.&lt;/p&gt; &lt;h2&gt;Re-creating the demo&lt;/h2&gt; &lt;p&gt;If you just want the source code, &lt;a href="https://github.com/jamesfalkner/microsweeper-demo"&gt;here it is&lt;/a&gt;, along with a &lt;em&gt;solution&lt;/em&gt; branch that adds the necessary changes to link the app to Cosmos DB and OpenShift. But if you want to play along, follow these steps:&lt;/p&gt; &lt;h3&gt;Step 1: Get an Azure account&lt;/h3&gt; &lt;p&gt;Our first job is to &lt;a href="https://azure.microsoft.com/en-us/free/"&gt;get an Azure account and some credits&lt;/a&gt;, all of which are free. Easy, right? Since we&amp;#8217;re using OpenShift, this could easily be deployed to the cloud of your choice, but Azure is super easy to use, and &lt;a href="https://azuremarketplace.microsoft.com/en-us/marketplace/apps/redhat.openshift-container-platform?tab=Overview"&gt;OpenShift is available in the Azure Marketplace&lt;/a&gt; for production-ready multi-node OpenShift deployments. There&amp;#8217;s also a nice &lt;a href="https://access.redhat.com/documentation/en-us/reference_architectures/2018/html/deploying_and_managing_openshift_3.9_on_azure/index"&gt;Reference Architecture&lt;/a&gt; for all the architects out there.&lt;/p&gt; &lt;h3&gt;Step 2: Deploy OpenShift&lt;/h3&gt; &lt;p&gt;Since this is a demo, we can take shortcuts, right? In this case, we don&amp;#8217;t need the full power of a fully armed and operational and productized multi-node OpenShift deployment, so I used a nice &amp;#8220;All in One&amp;#8221; Azure deployment that Cesar created. To deploy this, simply &lt;a href="https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fcealsair%2FMicroProfileOnAzure%2Fmaster%2Fallinone.json"&gt;click here&lt;/a&gt; (or click the &lt;strong&gt;Deploy to Azure&lt;/strong&gt; button below, which takes you to the Azure Portal along with a &lt;a href="https://github.com/cealsair/MicroProfileThorntailOnAzure/blob/master/allinone.json"&gt;payload&lt;/a&gt; that will deploy a single-node OpenShift instance to an Azure Resource Group of your choosing).&lt;/p&gt; &lt;p&gt;&lt;a href="https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Fcealsair%2FMicroProfileOnAzure%2Fmaster%2Fallinone.json"&gt;&lt;img class="alignnone" src="http://azuredeploy.net/deploybutton.png" alt="" width="161" height="34" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;You&amp;#8217;ll need to fill out some information as part of the install. You&amp;#8217;ll use these values later, so don&amp;#8217;t forget them:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Resource Group&lt;/strong&gt;: Create a new Resource Group to house all of the components (VMs, NICs, storage, etc).  Resource Groups are the way Azure groups related resources together. If the named group does not exist, it&amp;#8217;ll be created for you.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Location&lt;/strong&gt;: Pick one close to you to deploy.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Admin Username / Admin Password&lt;/strong&gt;: These will be the username and password you&amp;#8217;ll use to log in to the OpenShift Web Console.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Ssh Key Data&lt;/strong&gt;: You&amp;#8217;ll need to &lt;a href="https://docs.microsoft.com/en-us/azure/virtual-machines/linux/mac-create-ssh-keys"&gt;generate an SSH keypair&lt;/a&gt; if you want to use &lt;code&gt;ssh&lt;/code&gt; to access the resulting virtual machines.  Paste in the contents of the public key file once you&amp;#8217;ve created it.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Vm size&lt;/strong&gt;: Specify a VM size. A default value is provided. If another size or type of VM is required, ensure that the Location contains that instance type.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Agree to the terms and conditions, and click the &lt;strong&gt;Purchase&lt;/strong&gt; button. Then get a cup of coffee; it&amp;#8217;ll take around 15 minutes to complete and you&amp;#8217;ll start burning through your credits. (For the default machine type, you&amp;#8217;ll eat US$20 through US$30 per week!) Click the &lt;strong&gt;Deployment Progress&lt;/strong&gt; notification to watch the progress.&lt;/p&gt; &lt;p&gt;Once it is done, click on the &lt;strong&gt;Outputs&lt;/strong&gt; tab to reveal the URL to your new OpenShift console. Bookmark it, because you&amp;#8217;ll need it later. Also, don&amp;#8217;t forget the username/password you provided; you&amp;#8217;ll need those later too.&lt;/p&gt; &lt;p&gt;If you don&amp;#8217;t get any &lt;em&gt;outputs&lt;/em&gt;, you can always discover the public DNS hostname of your new OpenShift deployment by clicking on the &lt;strong&gt;Virtual Machines&lt;/strong&gt; link at the far left of the Azure Portal,  then click on the VM name (same name as the Resource Group you specified), then look for the &lt;em&gt;DNS Name&lt;/em&gt;, and open a new browser tab and navigate to &lt;code&gt;https://[THE_DNS_NAME]:8443&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Step 2a: Give yourself cluster-admin access&lt;/h3&gt; &lt;p&gt;Although a user in OpenShift was created using the credentials you supplied, this user does not have the &lt;code&gt;cluster-admin&lt;/code&gt; rights necessary for installing the service broker components. To give ourselves this ability, we need to use &lt;code&gt;ssh&lt;/code&gt; to access the machine and run a command (you &lt;i&gt;did&lt;/i&gt; save the SSH public and private key created earlier, right?).&lt;/p&gt; &lt;p&gt;First, log in to the VM running OpenShift:&lt;/p&gt; &lt;pre&gt;ssh -i [PRIVATE_KEY_PATH] [ADMIN_USERNAME]@[VM HOSTNAME] &lt;/pre&gt; &lt;p&gt;Where:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;[PRIVATE_KEY_PATH]&lt;/code&gt; is the path to the file containing the private key that corresponds to the public key you used when setting up OpenShift on Azure.&lt;/li&gt; &lt;li&gt;&lt;code&gt;[ADMIN_USERNAME]&lt;/code&gt; is the name of the OpenShift user you specified.&lt;/li&gt; &lt;li&gt;&lt;code&gt;[VM HOSTNAME]&lt;/code&gt; is the DNS hostname of the VM running on Azure.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Once logged in via &lt;code&gt;ssh&lt;/code&gt;, run this command:&lt;/p&gt; &lt;pre&gt;sudo oc adm policy add-cluster-role-to-user cluster-admin [ADMIN_USERNAME]&lt;/pre&gt; &lt;p&gt;&lt;code&gt;[ADMIN_USERNAME]&lt;/code&gt; is the same as what you used in the &lt;code&gt;ssh&lt;/code&gt; command. This will give you the needed rights to install the service broker in the next steps. You can exit the &lt;code&gt;ssh&lt;/code&gt; session now.&lt;/p&gt; &lt;h3&gt;Step 3: Deploy the Azure Service Broker&lt;/h3&gt; &lt;p&gt;Out of the box, this all-in-one deployment of OpenShift includes support for the OpenShift Service Catalog (our implementation of the Open Service Broker API), so all that is left to do is install the &lt;a href="https://github.com/Azure/open-service-broker-azure"&gt;Open Service Broker for Azure&lt;/a&gt; to expose Azure services in the OpenShift Service Catalog.&lt;/p&gt; &lt;p&gt;This can most easily by installed using &lt;a href="https://www.helm.sh/"&gt;Helm&lt;/a&gt; (here are &lt;a href="https://docs.helm.sh/using_helm/#installing-helm"&gt;installation instructions&lt;/a&gt;), and with Helm you can also choose which version of the broker. Microsoft has &lt;a href="https://github.com/Azure/open-service-broker-azure/releases/tag/v1.0.0"&gt;temporarily taken out experimental services&lt;/a&gt; from the GA version of the broker, and is slowly adding them back in, so you&amp;#8217;ll need to specify a version from earlier this year that includes these experimental services like Cosmos DB&amp;#8217;s MongoDB API, which the demo uses.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s first log in as our admin user to our newly deployed OpenShift deployment using the &lt;code&gt;oc&lt;/code&gt; command (if you don&amp;#8217;t have this command, install the &lt;em&gt;client tools&lt;/em&gt; from &lt;a href="https://www.okd.io/download.html"&gt;here&lt;/a&gt;):&lt;/p&gt; &lt;pre&gt;oc login [URL] -u [ADMIN_USERNAME] -p [PASSWORD]&lt;/pre&gt; &lt;p&gt;Here, you need to specify the URL (including port number 8443) to your new OpenShift instance, as well as the username/password you used earlier when setting it up on Azure.&lt;/p&gt; &lt;p&gt;Once logged in, let&amp;#8217;s deploy the broker with Helm (note that this uses Helm 2.x and it&amp;#8217;s Tiller-full implementation).&lt;/p&gt; &lt;pre&gt;oc create -f https://raw.githubusercontent.com/Azure/helm-charts/master/docs/prerequisities/helm-rbac-config.yaml helm init --service-account tiller helm repo add azure https://kubernetescharts.blob.core.windows.net/azure&lt;/pre&gt; &lt;p&gt;With Helm set up and the Azure Helm Charts added, it&amp;#8217;s time to install the &lt;a href="https://github.com/Azure/open-service-broker-azure"&gt;Open Service Broker for Azure&lt;/a&gt;, but you&amp;#8217;ll need &lt;em&gt;four special values&lt;/em&gt; that will associate the broker with your personal Azure account through what&amp;#8217;s called a &lt;em&gt;service principal&lt;/em&gt;. Service principals are entities that have an identity and permissions to create and edit resources on an application&amp;#8217;s behalf. &lt;a href="https://docs.microsoft.com/en-us/azure/azure-resource-manager/resource-group-create-service-principal-portal"&gt;You&amp;#8217;ll need to first create a service principal following the instructions here&lt;/a&gt;, and while creating it and assigning it permissions to your new Resource Group, collect the following values:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;AZURE_SUBSCRIPTION_ID&lt;/strong&gt;: This is associated with your Azure account and can be found on the &lt;a href="https://portal.azure.com"&gt;Azure Portal&lt;/a&gt; (after logging in) by clicking on &lt;strong&gt;Resource Groups&lt;/strong&gt; and then on the name of the resource group created when you deployed OpenShift using the All-In-One deployment. Example: &lt;code&gt;6ac2eb01-3342-4727-9dfa-48f54bba9726&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;strong&gt;AZURE_TENANT_ID&lt;/strong&gt;: When creating the service principal, you&amp;#8217;ll see a reference to a &lt;em&gt;Tenant ID&lt;/em&gt;, also called a &lt;em&gt;Directory ID&lt;/em&gt;. It will also look something like a subscription ID, but they are different! It is associated with the Active Directory instance you have in your account.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;AZURE_CLIENT_ID&lt;/strong&gt;: The ID of the client (application) you create when creating a service principal, sometimes called an &lt;em&gt;application ID&lt;/em&gt;, also similar in structure to the above IDs but different!&lt;/li&gt; &lt;li&gt;&lt;strong&gt;AZURE_CLIENT_SECRET&lt;/strong&gt;: The secret value for the client (application) you create when creating a service principal. This will be a long-ish base64-encoded string.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Wow, that was fun. With these values, we can now issue the magic &lt;code&gt;helm&lt;/code&gt; command to do the tasks and install the Open Service Broker for Azure:&lt;/p&gt; &lt;pre&gt;helm install azure/open-service-broker-azure --name osba --namespace osba \ --version 0.11.0 \ --set azure.subscriptionId=[AZURE_SUBSCRIPTION_ID] \ --set azure.tenantId=[AZURE_TENANT_ID] \ --set azure.clientId=[AZURE_CLIENT_ID] \ --set azure.clientSecret=[AZURE_CLIENT_SECRET] \ --set modules.minStability=EXPERIMENTAL&lt;/pre&gt; &lt;p&gt;Unfortunately, this uses an ancient version of Redis, so let&amp;#8217;s use a more recent version and, to simplify things, let&amp;#8217;s remove the need for persistent volumes (and never use this in production!):&lt;/p&gt; &lt;pre&gt;oc volume -n osba deployment/osba-redis --remove --name=redis-data oc patch -n osba deployment/osba-redis -p '{"spec": {"template": {"spec": {"containers":[{"name": "osba-redis", "image": "bitnami/redis:4.0.9"}]}}}}'&lt;/pre&gt; &lt;p&gt;This will install the Open Service Broker for Azure in the &lt;code&gt;osba&lt;/code&gt; Kubernetes namespace and enable the experimental features (like Cosmos DB).  It may take some time to pull the images for the broker and for Redis (the default database it uses), and the broker pod might enter a crash loop while it tries to access Redis, but eventually, it should come up. If you screw it up and get errors, you can start over by deleting the &lt;code&gt;osba&lt;/code&gt; namespace and trying again (using &lt;code&gt;helm del --purge osba; oc delete project osba&lt;/code&gt; and waiting a while until it&amp;#8217;s really gone and does not appear in &lt;code&gt;oc get projects&lt;/code&gt; output).&lt;/p&gt; &lt;p&gt;Run this command to verify everything is working:&lt;/p&gt; &lt;pre&gt;oc get pods -n osba&lt;/pre&gt; &lt;p&gt;You should see the following (look for the &lt;em&gt;Running&lt;/em&gt; status for both):&lt;/p&gt; &lt;pre&gt;NAME READY STATUS RESTARTS AGE osba-open-service-broker-azure-846688c998-p86bv 1/1 Running 4 1h osba-redis-5c7f85fcdf-s9xqk 1/1 Running 0 1h &lt;/pre&gt; &lt;p&gt;Now that it&amp;#8217;s installed, browse to the OpenShift Web Console (the URL can be discovered by running &lt;code&gt;oc status&lt;/code&gt;). Log in using the same credentials as before, and you should see a number of services and their icons for Azure services (it might take a minute or two for OpenShift to poll the broker and discover all it has to offer):&lt;/p&gt; &lt;div id="attachment_527067" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/osb.png"&gt;&lt;img class="wp-image-527067 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/osb-1024x799.png" alt="Azure Services exposed through Open Service Broker in OpenShift" width="640" height="499" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/osb-1024x799.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/osb-300x234.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/osb-768x599.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p class="wp-caption-text"&gt;Azure Services exposed through Open Service Broker in OpenShift&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Type &lt;code&gt;azure&lt;/code&gt; into the search box at the top to see a list. Woo! Easy, peasy.&lt;/p&gt; &lt;h3&gt;Step 4: Deploy Cosmos DB&lt;/h3&gt; &lt;p&gt;Before we deploy the app, let&amp;#8217;s deploy the database we&amp;#8217;ll use. (In the demo, I started without a database and did some live coding to deploy the database and change the app to use it. For this blog post, I&amp;#8217;ll assume you just want to run the final code.)&lt;/p&gt; &lt;p&gt;To deploy Cosmos DB, we&amp;#8217;ll use the OpenShift Web Console. On the main screen, double-click on the &lt;strong&gt;Azure Cosmos DB (MongoDB API) &lt;/strong&gt;icon. This will walk you through a couple of screens. Click &lt;strong&gt;Next&lt;/strong&gt; on the first screen. On the second screen, elect to deploy Cosmos DB to a new project, and name the project &lt;code&gt;microsweeper&lt;/code&gt;. Below that, you can keep all the default settings, except for the following:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Set &lt;strong&gt;defaultConsistencyLevel&lt;/strong&gt; to &lt;strong&gt;Session&lt;/strong&gt;.&lt;/li&gt; &lt;li&gt;Type &lt;code&gt;0.0.0.0/0&lt;/code&gt; in the first &lt;strong&gt;allowedIPRanges&lt;/strong&gt; box, and click the &lt;strong&gt;Add&lt;/strong&gt; button. Then click the &lt;strong&gt;X&lt;/strong&gt; button next to the second &lt;strong&gt;allowedIPRanges&lt;/strong&gt; box (don&amp;#8217;t ask why).&lt;/li&gt; &lt;li&gt;Enter a valid Azure region identifier in the &lt;strong&gt;location&lt;/strong&gt; box, for example, &lt;code&gt;eastus&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;In the &lt;strong&gt;resourceGroup&lt;/strong&gt; box, enter the name of the ResourceGroup you previously created in step 2.&lt;/li&gt; &lt;li&gt;Click &lt;strong&gt;Next&lt;/strong&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;On the final screen, choose the&lt;strong&gt; Create a secret in microsweeper to be used later&lt;/strong&gt; option. This will later be referenced from the app. Finally, click the &lt;strong&gt;Create&lt;/strong&gt; button and then OpenShift will do its thing, which will take about 5–10 minutes.&lt;/p&gt; &lt;p&gt;Click &lt;strong&gt;Continue to the project overview&lt;/strong&gt; to see the status of the Azure service. During this time, if you visit the Azure Portal in a separate tab, you&amp;#8217;ll see several resources being created (most notably a Cosmos DB instance). Once it&amp;#8217;s all done, the Provisioned Services section of the OpenShift Console&amp;#8217;s Project Overview screen will show that Cosmos DB is ready for use, including a binding that we&amp;#8217;ll use later.&lt;/p&gt; &lt;div id="attachment_525167" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.59.05-PM.png"&gt;&lt;img class="wp-image-525167 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.59.05-PM-1024x510.png" alt="Cosmos DB is ready for use" width="640" height="319" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.59.05-PM-1024x510.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.59.05-PM-300x150.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.59.05-PM-768x383.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.59.05-PM.png 1204w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p class="wp-caption-text"&gt;Cosmos DB is ready for use&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Step 5: Add MicroProfile health checks and configuration&lt;/h3&gt; &lt;p&gt;The app is using two of the &lt;a href="https://microprofile.io/projects/"&gt;many MicroProfile APIs&lt;/a&gt;: &lt;a href="https://microprofile.io/project/eclipse/microprofile-health"&gt;&lt;code&gt;HealthCheck&lt;/code&gt;&lt;/a&gt; and &lt;a href="https://microprofile.io/project/eclipse/microprofile-config"&gt;&lt;code&gt;Config&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt; &lt;h4&gt;MicroProfile HealthCheck&lt;/h4&gt; &lt;p&gt;To the &lt;a href="https://github.com/jamesfalkner/microsweeper-demo/blob/master/src/main/java/com/example/microsweeper/rest/RestApplication.java"&gt;&lt;code&gt;RestApplication&lt;/code&gt;&lt;/a&gt; class, we&amp;#8217;ve added a simple &lt;code&gt;@Health&lt;/code&gt; annotation and a new method:&lt;/p&gt; &lt;pre&gt;@Health @ApplicationPath("/api") public class RestApplication extends Application implements HealthCheck { @Override public HealthCheckResponse call() { return HealthCheckResponse.named("successful-check").up().build(); } } &lt;/pre&gt; &lt;p&gt;Simple, right? You can add as many of these as you want, and the health check can do whatever it needs to do and be as complex as you want (but not too complex!).&lt;/p&gt; &lt;h4&gt;MicroProfile Config&lt;/h4&gt; &lt;p&gt;More interesting I think is the addition of the Cosmos DB configuration. Since we exposed Cosmos DB through environment variables, we&amp;#8217;re able to automatically inject their values using MicroProfile in the &lt;a href="https://github.com/jamesfalkner/microsweeper-demo/blob/master/src/main/java/com/example/microsweeper/service/ScoreboardServiceCosmos.java"&gt;&lt;code&gt;ScoreboardServiceCosmos&lt;/code&gt;&lt;/a&gt; class:&lt;/p&gt; &lt;pre&gt;@Inject @ConfigProperty(name = "SCORESDB_uri") private String uri; ... mongoClient = new MongoClient(new MongoClientURI(uri)); &lt;/pre&gt; &lt;p&gt;The &lt;code&gt;@Inject @ConfigProperty&lt;/code&gt; MicroProfile annotations direct Thorntail to look for and dynamically inject values for the &lt;code&gt;uri&lt;/code&gt; field, based on the specified name. The MicroProfile &lt;code&gt;Config&lt;/code&gt; API specifies a well-defined precedence table to find these, so there are many ways to expose the values to your applications. We will use an environment variable in this demo, but you could also use properties files, &lt;a href="https://docs.okd.io/latest/dev_guide/configmaps.html"&gt;ConfigMaps&lt;/a&gt;, etc.&lt;/p&gt; &lt;h3&gt;Step 6: Deploy the App&lt;/h3&gt; &lt;p&gt;The sample app uses &lt;a href="https://thorntail.io"&gt;Thorntail&lt;/a&gt;, Red Hat&amp;#8217;s fully supported &lt;a href="https://microprofile.io"&gt;MicroProfile&lt;/a&gt; implementation. This is a Java framework, so you&amp;#8217;ll first need to install &lt;a href="https://developers.redhat.com/products/openjdk/overview/"&gt;Red Hat&amp;#8217;s OpenJDK&lt;/a&gt; to OpenShift so it can be used to build and run the app:&lt;/p&gt; &lt;pre&gt;oc create -n openshift -f https://raw.githubusercontent.com/jboss-openshift/application-templates/a1ea009fac7adf0ca34f8ab7dbe5aa0468fe5246/openjdk/openjdk18-image-stream.json&lt;/pre&gt; &lt;p&gt;This uses a previous version of the image stream that references &lt;a href="https://access.redhat.com/containers/"&gt;Red Hat Container Catalog&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Next, let&amp;#8217;s deploy the app to our newly created project:&lt;/p&gt; &lt;pre&gt;oc new-project microsweeper oc new-app 'redhat-openjdk18-openshift:1.3~https://github.com/jamesfalkner/microsweeper-demo#solution' \ -e GC_MAX_METASPACE_SIZE=500 \ -e ENVIRONMENT=DEVELOPMENT oc expose svc/microsweeper-demo &lt;/pre&gt; &lt;p&gt;This will create a new &lt;a href="https://docs.okd.io/latest/architecture/core_concepts/builds_and_image_streams.html#source-build"&gt;S2I-based build&lt;/a&gt; for the app, build it with Maven and OpenJDK, and deploy the app. Initially, the app will be using an internal database (H2). It may take a few minutes to deploy. When it&amp;#8217;s done, you should see the following output:&lt;/p&gt; &lt;pre&gt;% oc get pods -n microsweeper NAME READY STATUS RESTARTS AGE microsweeper-demo-1-build 0/1 Completed 0 1h microsweeper-demo-3-x8bdg 1/1 Running 0 1h &lt;/pre&gt; &lt;p&gt;You can see the completed build pod that built the app and the running app pod.&lt;/p&gt; &lt;div id="attachment_525077" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/azure.png"&gt;&lt;img class="wp-image-525077 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/azure-1024x609.png" alt="MicroProfile app deployed to OpenShift" width="640" height="381" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/azure-1024x609.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/azure-300x179.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/azure-768x457.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/azure.png 1163w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p class="wp-caption-text"&gt;MicroProfile app deployed to OpenShift&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Once deployed, you can click on the Route URL in the OpenShift Web Console next to the &lt;code&gt;microsweeper-demo&lt;/code&gt; service and play the game. You can also get the URL with this:&lt;/p&gt; &lt;pre&gt;echo http://$(oc get route microsweeper-demo -o jsonpath='{.spec.host}{"\n"}' -n microsweeper)&lt;/pre&gt; &lt;p&gt;Note that it is not yet using MicroProfile or Cosmos DB yet! In the game, enter your name (or use the default), and play the game a few times, ensuring that the scoreboard is updated when you win or lose. To reset the scoreboard, click the X in the upper right. To start the game again, click the smiley or sad face. Good times, right? Let&amp;#8217;s hook it up to Cosmos DB!&lt;/p&gt; &lt;h3&gt;Step 7: Bind Cosmos DB to the app&lt;/h3&gt; &lt;p&gt;In a previous step, you deployed the Cosmos DB service to your project, so it is now said to be &amp;#8220;provisioned&amp;#8221; and bound to the project. You could at this point hard-code the app logic to use the provisioned service&amp;#8217;s URI, username, password, etc., but that&amp;#8217;s a terrible long-term approach. It&amp;#8217;s better to expose the service&amp;#8217;s credentials dynamically using OpenShift and then change the app to use the values through that dynamic mechanism.&lt;/p&gt; &lt;p&gt;There are two easy ways to expose the service&amp;#8217;s configuration: through &lt;a href="https://kubernetes.io/docs/concepts/configuration/secret/"&gt;Kubernetes Secrets&lt;/a&gt; (where the credentials are exposed through an ordinary file on the filesystem securely transmitted and mounted via a volume in the pod) or through environment variables. I used environment variables because it&amp;#8217;s easy, but Thorntail/MicroProfile can use either.&lt;/p&gt; &lt;p&gt;First, click on &lt;strong&gt;View Secret&lt;/strong&gt; to view the contents of the secrets we need to bind to Cosmos DB, and then click on &lt;strong&gt;Add to Application&lt;/strong&gt;. This will allow you to choose for which application to add the environment variables to the DeploymentConfig for the application. Select the &lt;code&gt;microsweeper-demo&lt;/code&gt; application in the drop-down, and then select the &lt;strong&gt;Environment variables&lt;/strong&gt; option and specify a prefix of &lt;code&gt;SCORESDB_&lt;/code&gt;. (Don&amp;#8217;t forget the underscore!) This will alter the environment of the application once it is re-deployed to add the new environment variables, each of which will start with &lt;code&gt;SCORESDB_&lt;/code&gt; (for example, the URI to the Cosmos DB will be the value of the &lt;code&gt;SCORESDB_uri&lt;/code&gt; environment variable).&lt;/p&gt; &lt;div id="attachment_525087" style="width: 648px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-4.45.14-PM.png"&gt;&lt;img class="wp-image-525087 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-4.45.14-PM.png" alt="Values to use when adding secrets to the app" width="638" height="349" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-4.45.14-PM.png 638w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-4.45.14-PM-300x164.png 300w" sizes="(max-width: 638px) 100vw, 638px" /&gt;&lt;/a&gt;&lt;p class="wp-caption-text"&gt;Values to use when adding secrets to the app&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Click &lt;strong&gt;Save&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;Now we&amp;#8217;re ready to switch to Cosmos DB. To do this switch, simply change the value of the &lt;code&gt;ENVIRONMENT&lt;/code&gt; environment variable to switch from the H2 database to Cosmos DB within the app:&lt;/p&gt; &lt;pre&gt;oc set env dc/microsweeper-demo ENVIRONMENT=PRODUCTION --overwrite&lt;/pre&gt; &lt;p&gt;At this point, the app will be re-deployed and start using Cosmos DB! Play the game a few more times, and then head over to the Azure Portal to verify data is being correctly persisted. Navigate to Azure Cosmos DB in the portal, and then click on the single long string that represents the ID of the database. You should see a single collection called &lt;em&gt;ScoresCollection&lt;/em&gt;:&lt;/p&gt; &lt;div id="attachment_525097" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.00.10-PM.png"&gt;&lt;img class="wp-image-525097 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.00.10-PM-1024x583.png" alt="A collection called ScoresCollection" width="640" height="364" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.00.10-PM-1024x583.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.00.10-PM-300x171.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.00.10-PM-768x437.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.00.10-PM.png 1580w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p class="wp-caption-text"&gt;A collection called ScoresCollection&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Click on &lt;strong&gt;ScoresCollection&lt;/strong&gt; and then on &lt;strong&gt;Data Explorer&lt;/strong&gt;. This tool lets you see the data records (documents) in the database.  Using the small &amp;#8220;&lt;strong&gt;&amp;#8230;&lt;/strong&gt;&amp;#8221; menu next to the name of the collection, click on &lt;strong&gt;New Query&lt;/strong&gt;:&lt;/p&gt; &lt;div id="attachment_525107" style="width: 430px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.32.44-PM.png"&gt;&lt;img class="wp-image-525107 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.32.44-PM.png" alt="Selecting the New Query menu item" width="420" height="303" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.32.44-PM.png 420w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.32.44-PM-300x216.png 300w" sizes="(max-width: 420px) 100vw, 420px" /&gt;&lt;/a&gt;&lt;p class="wp-caption-text"&gt;Selecting the New Query menu item&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Type the simplest of queries into the Query box: &lt;code&gt;{}&lt;/code&gt;. Then click &lt;strong&gt;Execute Query&lt;/strong&gt; to see the results. Play the game a few more times, and re-issue the query to confirm data is being persisted properly. Well done!&lt;/p&gt; &lt;div id="attachment_525117" style="width: 927px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.33.00-PM.png"&gt;&lt;img class="wp-image-525117 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.33.00-PM.png" alt="Confirming data is being persisted properly" width="917" height="440" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.33.00-PM.png 917w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.33.00-PM-300x144.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Screen-Shot-2018-10-05-at-5.33.00-PM-768x369.png 768w" sizes="(max-width: 917px) 100vw, 917px" /&gt;&lt;/a&gt;&lt;p class="wp-caption-text"&gt;Confirming data is being persisted properly&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Next Steps&lt;/h3&gt; &lt;p&gt;In this demo, we used two of the MicroProfile APIs that are instrumental in developing Java microservices (&lt;code&gt;HealthCheck&lt;/code&gt; and &lt;code&gt;Config&lt;/code&gt;) to link the MicroProfile/Thorntail application to Azure services through the Open Service Broker API.&lt;/p&gt; &lt;p&gt;There are many other MicroProfile APIs you can use, and I encourage you to check out the &lt;a href="https://microprofile.io/projects/"&gt;full specifications&lt;/a&gt; and the recent release (MicroProfile 2.1). MicroProfile is awesome and is a great way to build Java microservices using truly open, community-driven innovation.&lt;/p&gt; &lt;p&gt;Also see these posts on &lt;a href="https://developers.redhat.com/blog/category/modern-app-dev/"&gt;modern application development&lt;/a&gt;, &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt;, &lt;a href="https://developers.redhat.com/blog/category/containers/"&gt;containers&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/blog/category/java/"&gt;Java&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Happy coding!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fmicroprofile-apps-azure-open-service-broker%2F&amp;#38;linkname=Deploying%20MicroProfile%20apps%20on%20Microsoft%20Azure%20using%20the%20Azure%20Open%20Service%20Broker" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fmicroprofile-apps-azure-open-service-broker%2F&amp;#38;linkname=Deploying%20MicroProfile%20apps%20on%20Microsoft%20Azure%20using%20the%20Azure%20Open%20Service%20Broker" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fmicroprofile-apps-azure-open-service-broker%2F&amp;#38;linkname=Deploying%20MicroProfile%20apps%20on%20Microsoft%20Azure%20using%20the%20Azure%20Open%20Service%20Broker" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fmicroprofile-apps-azure-open-service-broker%2F&amp;#38;linkname=Deploying%20MicroProfile%20apps%20on%20Microsoft%20Azure%20using%20the%20Azure%20Open%20Service%20Broker" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fmicroprofile-apps-azure-open-service-broker%2F&amp;#38;linkname=Deploying%20MicroProfile%20apps%20on%20Microsoft%20Azure%20using%20the%20Azure%20Open%20Service%20Broker" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fmicroprofile-apps-azure-open-service-broker%2F&amp;#38;linkname=Deploying%20MicroProfile%20apps%20on%20Microsoft%20Azure%20using%20the%20Azure%20Open%20Service%20Broker" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fmicroprofile-apps-azure-open-service-broker%2F&amp;#38;linkname=Deploying%20MicroProfile%20apps%20on%20Microsoft%20Azure%20using%20the%20Azure%20Open%20Service%20Broker" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fmicroprofile-apps-azure-open-service-broker%2F&amp;#38;linkname=Deploying%20MicroProfile%20apps%20on%20Microsoft%20Azure%20using%20the%20Azure%20Open%20Service%20Broker" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F17%2Fmicroprofile-apps-azure-open-service-broker%2F&amp;#38;title=Deploying%20MicroProfile%20apps%20on%20Microsoft%20Azure%20using%20the%20Azure%20Open%20Service%20Broker" data-a2a-url="https://developers.redhat.com/blog/2018/10/17/microprofile-apps-azure-open-service-broker/" data-a2a-title="Deploying MicroProfile apps on Microsoft Azure using the Azure Open Service Broker"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/17/microprofile-apps-azure-open-service-broker/"&gt;Deploying MicroProfile apps on Microsoft Azure using the Azure Open Service Broker&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/rQnYQZWQQWE" height="1" width="1" alt=""/&gt;</content><summary>At the recently concluded Microsoft Ignite 2018 conference in Orlando, I had the honor of presenting to a crowd of Java developers and Azure professionals eager to learn how to put their Java skills to work building next-gen apps on Azure. Of course, that meant showcasing the technology coming out of the popular MicroProfile community, in which Red Hat plays a big part (and makes a fully supported...</summary><dc:creator>James Falkner</dc:creator><dc:date>2018-10-17T18:00:28Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/10/17/microprofile-apps-azure-open-service-broker/</feedburner:origLink></entry><entry><title>Last call for DMN webinar on October 18, 2018</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/uxGY0SnD6gs/last-call-for-dmn-webinar-on-october-18.html" /><category term="feed_group_name_drools" scheme="searchisko:content:tags" /><category term="feed_name_drools" scheme="searchisko:content:tags" /><author><name>Mario Fusco</name></author><id>searchisko:content:id:jbossorg_blog-last_call_for_dmn_webinar_on_october_18_2018</id><updated>2018-10-17T14:09:29Z</updated><published>2018-10-17T14:09:00Z</published><content type="html">Are you interested to know more on how Drools provides an open source execution engine with full DMN support at conformance level 3? This is your last change to register for tomorrow's &lt;a href="https://middlewareblog.redhat.com/2018/09/27/decision-model-notation-a-new-approach-to-business-rules/" target="_blank"&gt;free webinar&lt;/a&gt; presented by &lt;span class="author-wrap"&gt;&lt;span class="byline"&gt;&lt;span class="author vcard"&gt;Phil Simpson and &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="author-wrap"&gt;&lt;span class="byline"&gt;&lt;span class="author vcard"&gt;Denis Gagne &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span class="author-wrap"&gt;&lt;span class="byline"&gt;&lt;span class="author vcard"&gt;&lt;span class="author-wrap"&gt;&lt;span class="byline"&gt;&lt;span class="author vcard"&gt;on October 18 at 1pm ET.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;&lt;span class="author-wrap"&gt;&lt;span class="byline"&gt;&lt;span class="author vcard"&gt;&lt;span class="author-wrap"&gt;&lt;span class="byline"&gt;&lt;span class="author vcard"&gt;Don't miss it! &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=SAEpaMAGlzA:PVLFWusyU4c:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=SAEpaMAGlzA:PVLFWusyU4c:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?i=SAEpaMAGlzA:PVLFWusyU4c:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=SAEpaMAGlzA:PVLFWusyU4c:dnMXMwOfBR0"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?d=dnMXMwOfBR0" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=SAEpaMAGlzA:PVLFWusyU4c:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?i=SAEpaMAGlzA:PVLFWusyU4c:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=SAEpaMAGlzA:PVLFWusyU4c:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?i=SAEpaMAGlzA:PVLFWusyU4c:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=SAEpaMAGlzA:PVLFWusyU4c:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.athico.com/~ff/DroolsAtom?a=SAEpaMAGlzA:PVLFWusyU4c:jWeZv7XsJd0"&gt;&lt;img src="http://feeds.feedburner.com/~ff/DroolsAtom?d=jWeZv7XsJd0" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/DroolsAtom/~4/SAEpaMAGlzA" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/uxGY0SnD6gs" height="1" width="1" alt=""/&gt;</content><summary>Are you interested to know more on how Drools provides an open source execution engine with full DMN support at conformance level 3? This is your last change to register for tomorrow's free webinar presented by Phil Simpson and Denis Gagne on October 18 at 1pm ET. Don't miss it!</summary><dc:creator>Mario Fusco</dc:creator><dc:date>2018-10-17T14:09:00Z</dc:date><feedburner:origLink>http://feeds.athico.com/~r/DroolsAtom/~3/SAEpaMAGlzA/last-call-for-dmn-webinar-on-october-18.html</feedburner:origLink></entry><entry><title>Hibernate ORM 5.3.7.Final released</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/WzJi4o2jrsg/" /><category term="feed_group_name_hibernate" scheme="searchisko:content:tags" /><category term="feed_name_inrelationto" scheme="searchisko:content:tags" /><category term="Hibernate ORM" scheme="searchisko:content:tags" /><category term="releases" scheme="searchisko:content:tags" /><author><name>Guillaume Smet</name></author><id>searchisko:content:id:jbossorg_blog-hibernate_orm_5_3_7_final_released</id><updated>2018-10-17T10:20:23Z</updated><published>2018-10-17T00:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Today, we released a new maintenance release of Hibernate ORM 5.3: 5.3.7.Final.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="what-s-new"&gt;&lt;a class="anchor" href="#what-s-new"&gt;&lt;/a&gt;What’s new&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="sect2"&gt; &lt;h3 id="bug-fixes"&gt;&lt;a class="anchor" href="#bug-fixes"&gt;&lt;/a&gt;Bug fixes&lt;/h3&gt; &lt;div class="paragraph"&gt; &lt;p&gt;We fixed a couple of compatibility issues and bugs.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;You can find the full list of changes &lt;a href="https://hibernate.atlassian.net/projects/HHH/versions/31714/tab/release-report-all-issues"&gt;here&lt;/a&gt; (or, for people without a Hibernate Jira account, &lt;a href="https://hibernate.atlassian.net/secure/ReleaseNote.jspa?version=31714&amp;amp;styleName=Html&amp;amp;projectId=10031"&gt;here&lt;/a&gt;).&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="getting-5-3-7-final"&gt;&lt;a class="anchor" href="#getting-5-3-7-final"&gt;&lt;/a&gt;Getting 5.3.7.Final&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;All details are available and up to date on &lt;a href="http://hibernate.org/orm/releases/5.3/#get-it"&gt;the dedicated page on hibernate.org&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="what-s-next"&gt;&lt;a class="anchor" href="#what-s-next"&gt;&lt;/a&gt;What’s next?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;We are working on a 5.4 release which will contain more bugfixes, JDK 11 support improvements (see &lt;a href="http://in.relation.to/2018/09/13/using-hibernate-orm-with-jdk11/"&gt;here&lt;/a&gt; for how to use 5.3 with JDK 11) and some major improvements on entity graphs.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="feedback-issues-ideas"&gt;&lt;a class="anchor" href="#feedback-issues-ideas"&gt;&lt;/a&gt;Feedback, issues, ideas?&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;To get in touch, use the usual channels:&lt;/p&gt; &lt;/div&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/tagged/hibernate"&gt;&lt;strong&gt;hibernate&lt;/strong&gt; tag on Stack Overflow&lt;/a&gt; (usage questions)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/c/hibernate-orm"&gt;User forum&lt;/a&gt; (usage questions, general feedback)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://hibernate.atlassian.net/browse/HHH"&gt;Issue tracker&lt;/a&gt; (bug reports, feature requests)&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://lists.jboss.org/pipermail/hibernate-dev/"&gt;Mailing list&lt;/a&gt; (development-related discussions)&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/WzJi4o2jrsg" height="1" width="1" alt=""/&gt;</content><summary>Today, we released a new maintenance release of Hibernate ORM 5.3: 5.3.7.Final. What’s new Bug fixes We fixed a couple of compatibility issues and bugs. You can find the full list of changes here (or, for people without a Hibernate Jira account, here). Getting 5.3.7.Final All details are available and up to date on the dedicated page on hibernate.org. What’s next? We are working on a 5.4 release w...</summary><dc:creator>Guillaume Smet</dc:creator><dc:date>2018-10-17T00:00:00Z</dc:date><feedburner:origLink>http://in.relation.to/2018/10/17/hibernate-orm-537-final-out/</feedburner:origLink></entry><entry><title>EclipseCon Europe: Che sessions by Red Hatters</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/LxlIMDPmWTc/" /><category term="Che" scheme="searchisko:content:tags" /><category term="community" scheme="searchisko:content:tags" /><category term="Conferences" scheme="searchisko:content:tags" /><category term="Developer Events" scheme="searchisko:content:tags" /><category term="Developer Tools" scheme="searchisko:content:tags" /><category term="Eclipse" scheme="searchisko:content:tags" /><category term="Eclipse Che" scheme="searchisko:content:tags" /><category term="EclipseCon Europe" scheme="searchisko:content:tags" /><category term="events" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Theia" scheme="searchisko:content:tags" /><author><name>Doug Tidwell</name></author><id>searchisko:content:id:jbossorg_blog-eclipsecon_europe_che_sessions_by_red_hatters</id><updated>2018-10-16T17:27:46Z</updated><published>2018-10-16T17:27:46Z</published><content type="html">&lt;p&gt;&lt;a href="https://www.eclipsecon.org/europe2018"&gt;EclipseCon Europe&lt;/a&gt; is almost here, and many Red Hatters are working furiously to make the show as valuable as possible for attendees. (We&amp;#8217;re partly doing it for ourselves as well, of course, because it&amp;#8217;s a great opportunity to get the entire &lt;a href="https://developers.redhat.com/blog/category/community/eclipse-che/"&gt;Che&lt;/a&gt;/Theia community together.)  If you aren&amp;#8217;t familiar with Eclipse Che, it&amp;#8217;s is a next-generation cloud IDE and developer workspace server for teams and organizations. Theia is an extensible open-source framework to develop multi-language IDEs for the cloud and desktop using state-of-the-art web technologies.&lt;/p&gt; &lt;p&gt;The conference will be held next week on October 22–25 in Ludwigsburg, Germany. Here&amp;#8217;s a rundown of what will be offered.&lt;span id="more-528177"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;First, on Monday, October 22nd is the &lt;a href="https://www.eclipsecon.org/europe2018/eclipse-che-theia-contributor-summit"&gt;Che and Theia Contributor Summit&lt;/a&gt;, featuring luminaries from across the community. The day starts with sessions on Theia internals and customizing your experience with Theia, continues with presentations on how to deploy developer tools in sidecar containers and work that is being done to enable Che to run on any Kubernetes distribution. You can also take a tutorial to learn how to develop a plug-in for Che, including extending both the server side and client side. And that&amp;#8217;s just the morning.&lt;/p&gt; &lt;p id="d9c3" class="graf graf--p graf-after--p"&gt;After lunch, we&amp;#8217;ll hear about the experiences of community members who are extending the developer experience on Che and Theia with language servers, debuggers, and modeling and tracing tools. “Enterprise ready” is a term that gets thrown around a lot in the world of IT products, and the afternoon features a presentation on what a developer platform for enterprise application development should be in terms of security, scalability, reliability, and other features.&lt;/p&gt; &lt;p class="graf graf--p graf-after--p"&gt;Finally, we end the day with collaborative community sessions sketching the future direction of both projects, before adjourning to the Eclipse Community Day meet-and-greet reception.&lt;/p&gt; &lt;p&gt;The conference proper runs from Tuesday (October 23) through Thursday (October 25). Here are some of the Che-related sessions and tutorials Red Hatters will be presenting:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Three-hour tutorial: &lt;a href="https://www.eclipsecon.org/europe2018/sessions/extending-eclipse-che-fun-and-profit"&gt;Extending Eclipse Che for fun and profit&lt;/a&gt;, Gorkem Ercan and Florent Benoit, Tuesday from 09:00–12:00&lt;/li&gt; &lt;li&gt;Presentation: &lt;a href="https://www.eclipsecon.org/europe2018/sessions/making-eclipse-che-enterprise-grade-sponsored-eclipse-che"&gt;Making Eclipse Che enterprise-grade&lt;/a&gt;, Dave Neary and Gorken Ercan, Wednesday from 11:10–11:45&lt;/li&gt; &lt;li&gt;Presentation: &lt;a href="https://www.eclipsecon.org/europe2018/sessions/beyond-lsp-extensions-java"&gt;Beyond LSP: Extensions for Java&lt;/a&gt;, Thomas Mäder, Wednesday from 10:25–11:00&lt;/li&gt; &lt;li&gt;Presentation: &lt;a href="https://www.eclipsecon.org/europe2018/sessions/eclipse-che-theia-ide-steroids"&gt;Eclipse Che: Theia IDE on steroids&lt;/a&gt;, Florent Benoit and Yevhen Vydolob, Wednesday from 15:45–16:20&lt;/li&gt; &lt;li&gt;Keynote: &lt;a href="https://www.eclipsecon.org/europe2018/sessions/lessons-open-source-25-year-old-company"&gt;Lessons on open source from a 25-year-old company&lt;/a&gt;, Harish Pillay, Thursday from 09:00–09:45&lt;/li&gt; &lt;li&gt;Presentation: &lt;a href="https://www.eclipsecon.org/europe2018/sessions/when-changing-theme-not-enough-swapping-your-ide-eclipse-che"&gt;When changing theme is not enough: Swapping your IDE in Eclipse Che&lt;/a&gt;, Oleksandr Garagatyi and Sergii Leshchenko, Thursday from 10:00–10:35&lt;/li&gt; &lt;li&gt;Presentation: &lt;a href="https://www.eclipsecon.org/europe2018/sessions/benefits-eclipse-che-when-developing-microservices-apps"&gt;Benefits of Eclipse Che when developing microservices apps&lt;/a&gt;, Eugene Ivantsov, Thursday from 10:45–11:20&lt;/li&gt; &lt;li&gt;Presentation: &lt;a href="http://www.eclipsecon.org/europe2018/sessions/adopting-language-server-apache-camel-feedback-javaeclipse-plugin-developer"&gt;Adopting Language Server for Apache Camel: feedback from a Java/Eclipse plugin developer perspective&lt;/a&gt;, Aurélien Pupier, Thursday from 14:00–14:35&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The conference is shaping up to be a great week for the community. You can still &lt;a href="https://www.eclipsecon.org/europe2018/registration"&gt;register&lt;/a&gt; and attend. We hope to see you next week in Ludwigsburg!&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F16%2Feclipsecon-eclipse-che-red-hat%2F&amp;#38;linkname=EclipseCon%20Europe%3A%20Che%20sessions%20by%20Red%20Hatters" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F16%2Feclipsecon-eclipse-che-red-hat%2F&amp;#38;linkname=EclipseCon%20Europe%3A%20Che%20sessions%20by%20Red%20Hatters" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F16%2Feclipsecon-eclipse-che-red-hat%2F&amp;#38;linkname=EclipseCon%20Europe%3A%20Che%20sessions%20by%20Red%20Hatters" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F16%2Feclipsecon-eclipse-che-red-hat%2F&amp;#38;linkname=EclipseCon%20Europe%3A%20Che%20sessions%20by%20Red%20Hatters" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F16%2Feclipsecon-eclipse-che-red-hat%2F&amp;#38;linkname=EclipseCon%20Europe%3A%20Che%20sessions%20by%20Red%20Hatters" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F16%2Feclipsecon-eclipse-che-red-hat%2F&amp;#38;linkname=EclipseCon%20Europe%3A%20Che%20sessions%20by%20Red%20Hatters" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F16%2Feclipsecon-eclipse-che-red-hat%2F&amp;#38;linkname=EclipseCon%20Europe%3A%20Che%20sessions%20by%20Red%20Hatters" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F16%2Feclipsecon-eclipse-che-red-hat%2F&amp;#38;linkname=EclipseCon%20Europe%3A%20Che%20sessions%20by%20Red%20Hatters" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F16%2Feclipsecon-eclipse-che-red-hat%2F&amp;#38;title=EclipseCon%20Europe%3A%20Che%20sessions%20by%20Red%20Hatters" data-a2a-url="https://developers.redhat.com/blog/2018/10/16/eclipsecon-eclipse-che-red-hat/" data-a2a-title="EclipseCon Europe: Che sessions by Red Hatters"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/16/eclipsecon-eclipse-che-red-hat/"&gt;EclipseCon Europe: Che sessions by Red Hatters&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/LxlIMDPmWTc" height="1" width="1" alt=""/&gt;</content><summary>EclipseCon Europe is almost here, and many Red Hatters are working furiously to make the show as valuable as possible for attendees. (We’re partly doing it for ourselves as well, of course, because it’s a great opportunity to get the entire Che/Theia community together.)  If you aren’t familiar with Eclipse Che, it’s is a next-generation cloud IDE and developer workspace server for teams and organ...</summary><dc:creator>Doug Tidwell</dc:creator><dc:date>2018-10-16T17:27:46Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/10/16/eclipsecon-eclipse-che-red-hat/</feedburner:origLink></entry><entry><title>EventFlow: Event-driven microservices on OpenShift (Part 1)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gTleEq_ns84/" /><category term="Apache Kafka" scheme="searchisko:content:tags" /><category term="Cloud Native" scheme="searchisko:content:tags" /><category term="CloudEvents" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="Developer Tools" scheme="searchisko:content:tags" /><category term="event processing" scheme="searchisko:content:tags" /><category term="event-driven architecture" scheme="searchisko:content:tags" /><category term="EventFlow" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="jboss a-mq" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="OpenShift Container Platform" scheme="searchisko:content:tags" /><category term="Red Hat AMQ" scheme="searchisko:content:tags" /><category term="serverless" scheme="searchisko:content:tags" /><category term="Stream Processing" scheme="searchisko:content:tags" /><category term="streams" scheme="searchisko:content:tags" /><author><name>Hugo Hiden</name></author><id>searchisko:content:id:jbossorg_blog-eventflow_event_driven_microservices_on_openshift_part_1</id><updated>2018-10-15T11:00:20Z</updated><published>2018-10-15T11:00:20Z</published><content type="html">&lt;p&gt;This post is the first in a series of three related posts that describes a lightweight cloud-native distributed &lt;a href="https://developers.redhat.com/topics/microservices/"&gt;microservices&lt;/a&gt; framework we have created called EventFlow. EventFlow can be used to develop streaming applications that can process &lt;a href="https://cloudevents.io"&gt;CloudEvents&lt;/a&gt;, which are an effort to standardize upon a data format for exchanging information about events generated by cloud platforms.&lt;/p&gt; &lt;p&gt;The EventFlow platform was created to specifically target the &lt;a href="https://developers.redhat.com/topics/kubernetes/"&gt;Kubernetes&lt;/a&gt;/&lt;a href="http://openshift.com/"&gt;OpenShift&lt;/a&gt; platforms, and it models event-processing applications as a connected flow or stream of components. The development of these components can be facilitated through the use of a simple SDK library, or they can be created as Docker images that can be configured using environment variables to attach to Kafka topics and process event data directly.&lt;/p&gt; &lt;p&gt;&lt;span id="more-523017"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Background&lt;/h2&gt; &lt;p&gt;Event processing is a methodology for reasoning about streams of potentially real-time events and data and generating conclusions based on both their absolute values and their temporal characteristics. Streams of events can come from many sources; they could be generated by parts of an organization (for example, patterns of orders, sales calls. etc.), they could be aggregated from external sources (for example, occurrences of news items, stock prices, etc.), collected from sensors (Internet-of-Things applications have the potential to generate vast quantities of streaming data), or even emitted by changes occurring within a cloud hosting platform.&lt;/p&gt; &lt;p&gt;Despite the attraction of being able to react in real time to streams of information, the actual process of creating and deploying event-driven systems is complex. In addition to managing the actual business logic for event processing, there are additional considerations to take into account when deploying this logic to produce a functioning system:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Code must be built and packaged in a form suitable for deployment within a container environment. This is largely dealt with using tooling such as Maven with the relevant plugins (typically, the &lt;a href="https://maven.fabric8.io/"&gt;fabric8 plugin&lt;/a&gt;). However, the responsibility of installing and connecting to the underlying messaging middleware is still the responsibility of the developer.&lt;/li&gt; &lt;li&gt;The process of modifying and scaling applications needs to be carefully managed. Adding additional compute resources to ease bottlenecks requires new resources to be brought on-stream and integrated into a running system without interfering with existing operations. Likewise, removing surplus resources needs to be done in a way that doesn’t affect the overall semantics of the application. This is particularly significant if the additional resources are located in remote cloud platforms (for example, a cloud bursting operation).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Given the benefits and challenges associated with efficiently processing event data, it is not surprising that a large number of platforms have been created.&lt;/p&gt; &lt;p&gt;It is important to realize that we made no attempt to re-create the functionality offered by libraries such as the Apache Kafka Streams API. Instead, we created a framework for connecting streaming components (some of which may themselves contain Apache Kafka Streams API code) into a coherent data flow that can be deployed and managed in a container platform.&lt;/p&gt; &lt;p&gt;Also, the framework described in this post was designed specifically to operate at scale within a container platform and was written using an entirely cloud-native approach. This approach has a number of distinct advantages:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Container platforms are well suited to dealing with varying levels of load because the architecture makes it extremely easy to scale up or down parts of an application in response to different levels of demand.&lt;/li&gt; &lt;li&gt;By adopting a cloud-native first approach, we can leverage the various management, data representation, and monitoring tools that are already provided by the container platform.&lt;/li&gt; &lt;li&gt;The inherent flexibility in terms of implementation languages afforded by a platform such as OpenShift means that applications can be built using a variety of different toolkits and languages and still operate on the same stream of events.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In this post, we will focus on processing &lt;a href="https://cloudevents.io/"&gt;CloudEvents&lt;/a&gt;, which provide a standard mechanism for describing event data in a platform-independent manner. The CloudEvents specification aims to make it easier to write portable applications that produce and consume event-based services. The specification provides a base level of metadata, which might be of interest for an event, and the payload, which can be of arbitrary structure. CloudEvents are distinct from a binding to any particular serialization format, but the event-flow platform uses a &lt;a href="https://github.com/project-streamzi/jcloudevents"&gt;JSON representation&lt;/a&gt; of them. Even though we are focussing on CloudEvents in this post, the EventFlow platform is not specific to them. It can be used to transport any other type of &amp;#8220;serializable&amp;#8221; data between processors.&lt;/p&gt; &lt;h2&gt;EventFlow architecture&lt;/h2&gt; &lt;p&gt;For the purposes of the EventFlow platform, an application is modelled as a connected set of processors (P&lt;sub&gt;1&lt;/sub&gt;,P&lt;sub&gt;2,&lt;/sub&gt; and P&lt;sub&gt;3&lt;/sub&gt;). Event data flows between these processors along logical connections (C&lt;sub&gt;1&lt;/sub&gt; and C&lt;sub&gt;2&lt;/sub&gt;):&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow-1.png"&gt;&lt;img class=" aligncenter wp-image-523057 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow-1.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow-1.png" alt="Diagram showing how event data flows between processors along logical connections" width="503" height="161" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow-1.png 503w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow-1-300x96.png 300w" sizes="(max-width: 503px) 100vw, 503px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&amp;#160;&lt;/p&gt; &lt;p&gt;In order to participate in such a flow, any code written by a developer needs to fit into one of three categories:&lt;/p&gt; &lt;ul&gt; &lt;li style="list-style-type: none;"&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;&lt;em&gt;Data Source:&lt;/em&gt;&lt;/strong&gt; Code that falls into this category produces a stream of data that is passed to other processors via a connection. Data sources are typically located at the beginning of an event flow and can be thought of as a bridge between an external system and the stream processing application.&lt;/li&gt; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Data Sink:&lt;/strong&gt;&lt;/em&gt; Data Sinks receive data from other processors in a flow and act upon it without any more downstream flow operations. An example of a Data Sink could be code that receives data at the end of a flow and inserts results into a database.&lt;/li&gt; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Data Processor:&lt;/strong&gt;&lt;/em&gt; Data Processors act as both a Data Source and Data Sink processing a stream of input event data and producing a stream of output data. An example of a Data Processor could be an operation that filters a stream of raw data for significant events that are passed to the output stream for further downstream processing.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Because the components within a flow are deployed as OpenShift pods, we can support varying levels of message throughput, by increasing or decreasing the number of deployed pods for each component. For example, a flow containing a computationally expensive step (P&lt;sub&gt;2&lt;/sub&gt; in the figure below) could have extra replicas of the bottleneck processor deployed to cope with the throughput. (EventFlow supports replicas deployed both in the local cloud environment and/or in remote cloud environments):&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Replicas.png"&gt;&lt;img class=" aligncenter wp-image-523067 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Replicas.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Replicas.png" alt="Diagram of extra replicas of a bottleneck processor deployed to cope with the throughput" width="499" height="185" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Replicas.png 499w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Replicas-300x111.png 300w" sizes="(max-width: 499px) 100vw, 499px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;In order to connect processors together and the manage the distribution of events between replicas, we make use of Apache Kafka (as provided by the &lt;a href="https://developers.redhat.com/products/amq/overview/"&gt;Red Hat AMQ Streams&lt;/a&gt; product) deployed within the container platform. For the example shown in the first figure, the two inter-processor connections (C&lt;sub&gt;1&lt;/sub&gt; and C&lt;sub&gt;2&lt;/sub&gt;) are represented using two separate Kafka topics.&lt;/p&gt; &lt;p&gt;When a flow is deployed within the container platform, the components within the flow are represented as follows:&lt;/p&gt; &lt;ul&gt; &lt;li style="list-style-type: none;"&gt; &lt;ul&gt; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Flow:&lt;/strong&gt;&lt;/em&gt; The definition of the flow (whether it is created using a graphical editor or from the Kubernetes k8s API) is stored as a Custom Resource within the container platform.&lt;/li&gt; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Processor:&lt;/strong&gt;&lt;/em&gt; Processors are deployed as containers within OpenShift. During the process of developing a Processor, a Docker image is created and uploaded to a registry. Deployed replicas of this image are responsible for performing the actual processing tasks.&lt;/li&gt; &lt;li&gt;&lt;em&gt;&lt;strong&gt;Connections:&lt;/strong&gt;&lt;/em&gt; The process of deploying the Kafka topics that represent connections within the data flow involves creating a Custom Resource for each Topic. Red Hat AMQ Streams contains an operator that responds to changes in these Custom Resources by creating, removing, or modifying the appropriate Kafka topics.&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;These concepts are illustrated below:&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Full.png"&gt;&lt;img class=" aligncenter wp-image-523077 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Full.png" src="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Full.png" alt="Diagram of the components within a flow" width="880" height="521" srcset="https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Full.png 880w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Full-300x178.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2018/10/Blog-Post_-CloudEvent-Flow_Full-768x455.png 768w" sizes="(max-width: 880px) 100vw, 880px" /&gt;&lt;/a&gt;&lt;/p&gt; &lt;h2&gt;Developing, designing, deploying, and managing flows&lt;/h2&gt; &lt;p&gt;Given the high-level overview presented above, making use of the event-flow platform requires developers to consider a set of tasks ranging from the development of event processing code to the management of deployed replicas and connections to remote clouds.&lt;/p&gt; &lt;h3&gt;Develop: Maven archetypes for developing processors&lt;/h3&gt; &lt;p&gt;Maven archetypes can be used to provide scaffolding for developers creating processors that the event flow can include. The event-flow SDK provides interfaces that can be used to produce and consume CloudEvents with very little effort from the developer. For example, the following code will log the events it receives. The event-flow runtime is responsible for configuring the processor with the input/output connection details and any settings the developer requires.&lt;/p&gt; &lt;pre class="brush: jscript; title: ; notranslate"&gt; @CloudEventComponent public class EchoingProcessor { Logger logger = Logger.getLogger(DataLogger.class.getName()); @CloudEventProducer(name = &amp;#34;OUTPUT_DATA&amp;#34;) CloudEventProducerTarget target; @CloudEventConsumer(name = &amp;#34;INPUT_DATA&amp;#34;) public void onCloudEvent(CloudEvent evt){ if(evt.getData().isPresent()){ logger.info(evt.getData().get().toString()); } target.send(evt); } } &lt;/pre&gt; &lt;p&gt;The development of custom processors will be covered in depth in Part 3 of this series. Part 3 will also show how to develop processors in other languages.&lt;/p&gt; &lt;h3&gt;Design: EventFlow Manager API and UI&lt;/h3&gt; &lt;p&gt;Flows are represented internally as k8s Custom Resources. While these can be created via the standard k8s API and we provide Java classes for working with the CRD, this is not very convenient for most developers. To make it easier for developers to create and deploy flows, we have developed an initial web-based UI for creating flows graphically.&lt;/p&gt; &lt;p&gt;Using this tool, developers can select input topics that are already present in Red Hat AMQ Streams and connect them to processors that have been deployed into OpenShift. The Manager UI allows developers to set processor parameters and non-functional settings such as the number of replicas of each processor. It is likely that in the future the current prototype UI will be replaced with other tools that are more consistent and user-friendly.&lt;/p&gt; &lt;h3&gt;Deploy: Flow Operator&lt;/h3&gt; &lt;p&gt;The Flow Operator is deployed into OpenShift and is responsible for the deployment and configuration of Flows. The operator is notified when new Flow Custom Resources are deployed into the platform or when an existing one is updated. The Operator inspects the Flow CR (Custom Resource) and generates a set of resources (Deployments, ConfigMaps, and KafkaTopics) that can be deployed into OpenShift. In a new Flow deployment, these resources are created in the platform and the flow will begin to process data when it arrives on an input topic. In the case of reconfiguring an existing flow, the Operator will update only the components that have been changed, leaving the unchanged components &amp;#8220;as is.&amp;#8221; Such changes could be increasing the number of replicas of a processor or editing the flow definition to include additional processors.&lt;/p&gt; &lt;h3&gt;Connect: Making use of Red Hat AMQ Streams&lt;/h3&gt; &lt;p&gt;The EventFlow platform uses Red Hat AMQ Streams as the communication mechanism between microservices. This allows the platform to dynamically create topics as required and has some convenient properties with respect to deployment and reconfiguration.&lt;/p&gt; &lt;p&gt;The deployment of the flow processors may occur in any order dependant on factors such as whether any images are cached locally and the startup overhead for each container. Because Red Hat AMQ Streams will buffer the messages in between processors, we are able to instantiate the flow in any order with confidence that once upstream components have started, the messages will begin to flow.&lt;/p&gt; &lt;p&gt;Second, one of the properties of Apache Kafka that underlies Red Hat AMQ Streams is that it has the potential to store historical messages indefinitely. This feature means that if a new processor is added to a running flow, there is the potential to &amp;#8220;replay&amp;#8221; old messages through it and all downstream processors. This results in the reconfigured flow behaving as if it had been deployed initially.&lt;/p&gt; &lt;h2&gt;Additional resources&lt;/h2&gt; &lt;p&gt;Here are some additional Kafka posts that might be helpful:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/07/16/smart-meter-streams-kafka-openshift/"&gt;Smart-Meter Data Processing Using Apache Kafka on OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/05/31/introducing-the-kafka-cdi-library/"&gt;Introducing the Kafka-CDI Library&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2018/05/07/announcing-amq-streams-apache-kafka-on-openshift/"&gt;Announcing AMQ Streams: Apache Kafka on OpenShift&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This post presented a framework that is capable of processing streams of events using a set of components that are connected using an installation of Apache Kafka provided by the Red Hat AMQ Streams product. This approach to event processing allows developers to create simple components that can be wired together using either a graphical editor or via a flow definition document. This means that complex event-processing pipelines can be created relatively easily and then scaled in response to varying levels of demand or distributed over multiple cloud providers, as required.&lt;/p&gt; &lt;p&gt;The next posts in this series will describe the process of event-flow creation and deployment and also introduce the software development environment that enables developers to create their own processing components and link them together using this framework.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_google_plus" href="https://www.addtoany.com/add_to/google_plus?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="Google+" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;linkname=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2018%2F10%2F15%2Feventflow-event-driven-microservices-on-openshift-part-1%2F&amp;#38;title=EventFlow%3A%20Event-driven%20microservices%20on%20OpenShift%20%28Part%201%29" data-a2a-url="https://developers.redhat.com/blog/2018/10/15/eventflow-event-driven-microservices-on-openshift-part-1/" data-a2a-title="EventFlow: Event-driven microservices on OpenShift (Part 1)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2018/10/15/eventflow-event-driven-microservices-on-openshift-part-1/"&gt;EventFlow: Event-driven microservices on OpenShift (Part 1)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;RHD Blog&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gTleEq_ns84" height="1" width="1" alt=""/&gt;</content><summary>This post is the first in a series of three related posts that describes a lightweight cloud-native distributed microservices framework we have created called EventFlow. EventFlow can be used to develop streaming applications that can process CloudEvents, which are an effort to standardize upon a data format for exchanging information about events generated by cloud platforms. The EventFlow platfo...</summary><dc:creator>Hugo Hiden</dc:creator><dc:date>2018-10-15T11:00:20Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2018/10/15/eventflow-event-driven-microservices-on-openshift-part-1/</feedburner:origLink></entry><entry><title>My first visit to Belarus speaking at the JFuture conference</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/1JwjjP9KGsc/my-first-visit-to-belarus-speaking-at.html" /><category term="apache camel" scheme="searchisko:content:tags" /><category term="conference" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_clausibsen" scheme="searchisko:content:tags" /><category term="speaker" scheme="searchisko:content:tags" /><author><name>Claus Ibsen</name></author><id>searchisko:content:id:jbossorg_blog-my_first_visit_to_belarus_speaking_at_the_jfuture_conference</id><updated>2018-10-15T10:22:31Z</updated><published>2018-10-15T10:22:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;I just got back from Minsk, Belarus where I gave a workshop and a presentation at the &lt;a href="https://jfuture.by/"&gt;JFuture 2018&lt;/a&gt; conference.&lt;br /&gt;&lt;br /&gt;This was my first visit to Belarus, and its always good to see new parts of the world, and help spread the knowledge about our beloved integration software &lt;a href="http://camel.apache.org/"&gt;Apache Camel&lt;/a&gt;. I am traveling with Mr Camel so at the hotel we read the greeting card from the organisers.&lt;br /&gt;&lt;div&gt;&amp;nbsp;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-kroh2dos5n0/W8RmBG_zwyI/AAAAAAAABvE/CeLvwoIID7IGkivcrsLEemNBBS2P_5HBwCLcBGAs/s1600/Screen%2BShot%2B2018-10-15%2Bat%2B12.02.35.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="347" data-original-width="515" height="215" src="https://1.bp.blogspot.com/-kroh2dos5n0/W8RmBG_zwyI/AAAAAAAABvE/CeLvwoIID7IGkivcrsLEemNBBS2P_5HBwCLcBGAs/s320/Screen%2BShot%2B2018-10-15%2Bat%2B12.02.35.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;br /&gt;On friday I hosted an Apache Camel microservices workshop with 10 Java developers whom were introduced to Apache Camel and then had fun hacking some Camel microservices code. The material is awesome and much credit to &lt;a href="https://github.com/nicolaferraro/camel-workshop"&gt;Nicola Ferraro&lt;/a&gt; for creating the workshop demo, which we joined presented earlier this year at JBCNConf in Barcelona.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-wy2HKSJcNoM/W8RmBV0UChI/AAAAAAAABvg/iMTglewKC3MwApe6VcG0cInHHttEi5hhgCEwYBhgL/s1600/Screen%2BShot%2B2018-10-15%2Bat%2B12.02.25.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="344" data-original-width="513" height="214" src="https://4.bp.blogspot.com/-wy2HKSJcNoM/W8RmBV0UChI/AAAAAAAABvg/iMTglewKC3MwApe6VcG0cInHHttEi5hhgCEwYBhgL/s320/Screen%2BShot%2B2018-10-15%2Bat%2B12.02.25.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;After the workshop I went out for a run in the city, mostly in the lovely parks. The weather was beautify with sun and 15 degrees celcius. The parks are full of tree leaves as the season is autumn.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-Gig7CFJ0zu8/W8Rnb1T7l5I/AAAAAAAABvo/0SDAq65qCKgpHuhu5kZknQWPJePidoqVwCLcBGAs/s1600/minsik-run.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="500" data-original-width="661" height="242" src="https://3.bp.blogspot.com/-Gig7CFJ0zu8/W8Rnb1T7l5I/AAAAAAAABvo/0SDAq65qCKgpHuhu5kZknQWPJePidoqVwCLcBGAs/s320/minsik-run.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-Um0-ez5IhSY/W8RjsX89dWI/AAAAAAAABuk/jGHK9L-yYxwBB65LWZvV3onyFu9oQXvAgCEwYBhgL/s1600/IMG_7346.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1600" data-original-width="1200" height="320" src="https://1.bp.blogspot.com/-Um0-ez5IhSY/W8RjsX89dWI/AAAAAAAABuk/jGHK9L-yYxwBB65LWZvV3onyFu9oQXvAgCEwYBhgL/s320/IMG_7346.JPG" width="240" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-KULIy6Pkaf8/W8Rjuc3kmrI/AAAAAAAABu4/xQlY0kaAnmsh5BZKukbl3gv9u9v3SFn5ACEwYBhgL/s1600/IMG_7350.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1200" data-original-width="1600" height="240" src="https://1.bp.blogspot.com/-KULIy6Pkaf8/W8Rjuc3kmrI/AAAAAAAABu4/xQlY0kaAnmsh5BZKukbl3gv9u9v3SFn5ACEwYBhgL/s320/IMG_7350.JPG" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-Nl6lotHe3DY/W8RjuPBJ3wI/AAAAAAAABuk/LZ9EonYppYwnDNcNALfp3iSHsiWPTkiXQCEwYBhgL/s1600/IMG_7351.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1600" data-original-width="1200" height="320" src="https://2.bp.blogspot.com/-Nl6lotHe3DY/W8RjuPBJ3wI/AAAAAAAABuk/LZ9EonYppYwnDNcNALfp3iSHsiWPTkiXQCEwYBhgL/s320/IMG_7351.JPG" width="240" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-0FA6nM4LNH4/W8RjyDdPT5I/AAAAAAAABu8/dDSrVt8IiQcrQjJI61XbMsrbE9KMtURywCEwYBhgL/s1600/IMG_7358.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1600" data-original-width="1200" height="320" src="https://1.bp.blogspot.com/-0FA6nM4LNH4/W8RjyDdPT5I/AAAAAAAABu8/dDSrVt8IiQcrQjJI61XbMsrbE9KMtURywCEwYBhgL/s320/IMG_7358.JPG" width="240" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-J3mXUyWGhKg/W8RjxOWrcCI/AAAAAAAABuo/k5YRpubLj6QngPdgdcNRR8mhTJFL9DjuACEwYBhgL/s1600/IMG_7363.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1200" data-original-width="1600" height="240" src="https://3.bp.blogspot.com/-J3mXUyWGhKg/W8RjxOWrcCI/AAAAAAAABuo/k5YRpubLj6QngPdgdcNRR8mhTJFL9DjuACEwYBhgL/s320/IMG_7363.JPG" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-r0uvmz8lcvQ/W8RjyXvsOzI/AAAAAAAABu8/9O-0Xyg69awcGxj1T8IPLWkUBTHoTyOLgCEwYBhgL/s1600/IMG_7360.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1600" data-original-width="1200" height="320" src="https://3.bp.blogspot.com/-r0uvmz8lcvQ/W8RjyXvsOzI/AAAAAAAABu8/9O-0Xyg69awcGxj1T8IPLWkUBTHoTyOLgCEwYBhgL/s320/IMG_7360.JPG" width="240" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-K0FOjC5ZUpI/W8Rj2YuaD0I/AAAAAAAABu8/8T-QR7ovL6QEnrZg6LxqG7xI6mSVcCOXwCEwYBhgL/s1600/IMG_7423.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="256" data-original-width="192" src="https://1.bp.blogspot.com/-K0FOjC5ZUpI/W8Rj2YuaD0I/AAAAAAAABu8/8T-QR7ovL6QEnrZg6LxqG7xI6mSVcCOXwCEwYBhgL/s1600/IMG_7423.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;On Saturday it was conference day, and the venue is the royal theatre in Minsk.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-ZOniGXF2Tzc/W8RjydAICiI/AAAAAAAABuw/3Nq5sbCpzjI9LJRA4FtjW0zHruriKXLrwCEwYBhgL/s1600/IMG_7375.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="256" data-original-width="192" src="https://4.bp.blogspot.com/-ZOniGXF2Tzc/W8RjydAICiI/AAAAAAAABuw/3Nq5sbCpzjI9LJRA4FtjW0zHruriKXLrwCEwYBhgL/s1600/IMG_7375.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-J8RBjWWRmPE/W8RjypEa1sI/AAAAAAAABu0/Z-5STGIO3QIrKoFizzZVnjLQHYOsL4yGQCEwYBhgL/s1600/IMG_7376.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="256" data-original-width="192" src="https://2.bp.blogspot.com/-J8RBjWWRmPE/W8RjypEa1sI/AAAAAAAABu0/Z-5STGIO3QIrKoFizzZVnjLQHYOsL4yGQCEwYBhgL/s1600/IMG_7376.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;After they keynote we had the 1st set of tracks, and I was honoured to do my performance on the main stage.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-l_P7Md_JGe0/W8RjzCUUTQI/AAAAAAAABuk/WelZ0uk4-asU_IHkDqEWKcPLAougMs9HgCEwYBhgL/s1600/IMG_7385.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="591" data-original-width="332" height="320" src="https://3.bp.blogspot.com/-l_P7Md_JGe0/W8RjzCUUTQI/AAAAAAAABuk/WelZ0uk4-asU_IHkDqEWKcPLAougMs9HgCEwYBhgL/s320/IMG_7385.jpg" width="179" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;I was not the only red hatter, as Justin Lee, traveled all the way from New York to be here, and present about serverless.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-zm3JjYijlKQ/W8Rjy9fqfAI/AAAAAAAABu0/UYO2Sy0UVLYlpPxgvViF45_LE90eL7qFwCEwYBhgL/s1600/IMG_7384.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="256" data-original-width="192" src="https://4.bp.blogspot.com/-zm3JjYijlKQ/W8Rjy9fqfAI/AAAAAAAABu0/UYO2Sy0UVLYlpPxgvViF45_LE90eL7qFwCEwYBhgL/s1600/IMG_7384.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;For his presentation I got myself a seat in the balcony, which has a very nice view of the stage.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-BblaGxfnUzs/W8RmBU4nb8I/AAAAAAAABvc/h4f4kqsdhEQ3HK65qwLe115ClhcA9NCfwCEwYBhgL/s1600/Screen%2BShot%2B2018-10-15%2Bat%2B12.02.58.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="263" data-original-width="515" height="163" src="https://4.bp.blogspot.com/-BblaGxfnUzs/W8RmBU4nb8I/AAAAAAAABvc/h4f4kqsdhEQ3HK65qwLe115ClhcA9NCfwCEwYBhgL/s320/Screen%2BShot%2B2018-10-15%2Bat%2B12.02.58.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;I walked the city on the afternoon, and took some photos. After a couple of hours I found a nice place at the backside of the palace of the republic where I enjoyed a margarita, to celebrate my first visit here.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-iBpLVBTe_ts/W8RmB14KTkI/AAAAAAAABvY/WBYNiATSGIs4HBiVe0B7PuDntw3oESkBwCEwYBhgL/s1600/Screen%2BShot%2B2018-10-15%2Bat%2B12.03.06.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="264" data-original-width="515" height="164" src="https://1.bp.blogspot.com/-iBpLVBTe_ts/W8RmB14KTkI/AAAAAAAABvY/WBYNiATSGIs4HBiVe0B7PuDntw3oESkBwCEwYBhgL/s320/Screen%2BShot%2B2018-10-15%2Bat%2B12.03.06.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-CyWAJQg6SrM/W8RjurzZuuI/AAAAAAAABuo/OCUuj9OMilIhnZpInlNAD_j9QnG5lKe3QCEwYBhgL/s1600/IMG_7354.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1200" data-original-width="1600" height="240" src="https://2.bp.blogspot.com/-CyWAJQg6SrM/W8RjurzZuuI/AAAAAAAABuo/OCUuj9OMilIhnZpInlNAD_j9QnG5lKe3QCEwYBhgL/s320/IMG_7354.JPG" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-0FA6nM4LNH4/W8RjyDdPT5I/AAAAAAAABu8/dDSrVt8IiQcrQjJI61XbMsrbE9KMtURywCEwYBhgL/s1600/IMG_7358.JPG" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="1600" data-original-width="1200" height="320" src="https://1.bp.blogspot.com/-0FA6nM4LNH4/W8RjyDdPT5I/AAAAAAAABu8/dDSrVt8IiQcrQjJI61XbMsrbE9KMtURywCEwYBhgL/s320/IMG_7358.JPG" width="240" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-E5zhLZGaS14/W8Rj06ShRdI/AAAAAAAABuw/KUXJoFhokG87CyfziPQofpt4BlEhrk6GwCEwYBhgL/s1600/IMG_7404.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="256" data-original-width="192" src="https://4.bp.blogspot.com/-E5zhLZGaS14/W8Rj06ShRdI/AAAAAAAABuw/KUXJoFhokG87CyfziPQofpt4BlEhrk6GwCEwYBhgL/s1600/IMG_7404.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;I stayed at the Willing hotel which is located 20 minute walk from the city center. Its in an area with old factories that are now being put up for new use with startups and hipsters in the neighborhood. So there are many coffee shops and some bars. The big walls of these factories were painted by local and foreign artists.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-0ly9ZXc7Vyc/W8RjzfnoaKI/AAAAAAAABuo/bZvY20K_ORogKGJZzw2LO5CdoMue-izUACEwYBhgL/s1600/IMG_7387.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="192" data-original-width="256" src="https://2.bp.blogspot.com/-0ly9ZXc7Vyc/W8RjzfnoaKI/AAAAAAAABuo/bZvY20K_ORogKGJZzw2LO5CdoMue-izUACEwYBhgL/s1600/IMG_7387.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://2.bp.blogspot.com/-VOXt9n4KSOk/W8RjzcfUWOI/AAAAAAAABu4/LQ-qxywFbR87t5vJK1rsFtWQ-EsOGZG5gCEwYBhgL/s1600/IMG_7390.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="256" data-original-width="192" src="https://2.bp.blogspot.com/-VOXt9n4KSOk/W8RjzcfUWOI/AAAAAAAABu4/LQ-qxywFbR87t5vJK1rsFtWQ-EsOGZG5gCEwYBhgL/s1600/IMG_7390.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://3.bp.blogspot.com/-VCqgLTfUVek/W8RjzwcXFII/AAAAAAAABu0/QU424xUQU3ov8Bm97H-AgRTBHBxDVN1mACEwYBhgL/s1600/IMG_7396.jpg" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="192" data-original-width="256" src="https://3.bp.blogspot.com/-VCqgLTfUVek/W8RjzwcXFII/AAAAAAAABu0/QU424xUQU3ov8Bm97H-AgRTBHBxDVN1mACEwYBhgL/s1600/IMG_7396.jpg" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;I enjoyed my time in Minsk, and I would like to say a warm thanks to the organisers for inviting me to come. I wish you the best with the conference and can recommend it to other speakers.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=VkEM0eLw8BU:vPVqAwI-xxY:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=VkEM0eLw8BU:vPVqAwI-xxY:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=VkEM0eLw8BU:vPVqAwI-xxY:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=VkEM0eLw8BU:vPVqAwI-xxY:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=VkEM0eLw8BU:vPVqAwI-xxY:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=VkEM0eLw8BU:vPVqAwI-xxY:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=VkEM0eLw8BU:vPVqAwI-xxY:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/ApacheCamel/~4/VkEM0eLw8BU" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/1JwjjP9KGsc" height="1" width="1" alt=""/&gt;</content><summary>I just got back from Minsk, Belarus where I gave a workshop and a presentation at the JFuture 2018 conference. This was my first visit to Belarus, and its always good to see new parts of the world, and help spread the knowledge about our beloved integration software Apache Camel. I am traveling with Mr Camel so at the hotel we read the greeting card from the organisers.   On friday I hosted an Apa...</summary><dc:creator>Claus Ibsen</dc:creator><dc:date>2018-10-15T10:22:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/VkEM0eLw8BU/my-first-visit-to-belarus-speaking-at.html</feedburner:origLink></entry><entry><title>Launch of Business Applications</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/FkBeYf4Z7NA/launch-of-business-applications.html" /><category term="business_applications" scheme="searchisko:content:tags" /><category term="case_applications" scheme="searchisko:content:tags" /><category term="feed_group_name_jbossjbpmcommunity" scheme="searchisko:content:tags" /><category term="feed_name_swiderskimaciej" scheme="searchisko:content:tags" /><category term="get_started_jbpm" scheme="searchisko:content:tags" /><category term="jbpm_applications" scheme="searchisko:content:tags" /><category term="jbpm_guide" scheme="searchisko:content:tags" /><category term="start.jbpm.org" scheme="searchisko:content:tags" /><author><name>Maciej Swiderski</name></author><id>searchisko:content:id:jbossorg_blog-launch_of_business_applications</id><updated>2018-10-15T08:55:22Z</updated><published>2018-10-15T08:55:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;h2 style="text-align: center;"&gt;The time has come - Business Applications are here!!!&lt;/h2&gt;&lt;div style="text-align: center;"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div style="text-align: center;"&gt;It's a great pleasure to announce that the Business Applications are now officially launched and ready for you to get started.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-biy16tKbncA/W8RRPKk1ycI/AAAAAAAABhY/TVsY6ItbmxspsPf4fXb-SfvgZxaUFuDMACLcBGAs/s1600/start-jbpm-org.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"&gt;&lt;img border="0" data-original-height="497" data-original-width="877" height="361" src="https://1.bp.blogspot.com/-biy16tKbncA/W8RRPKk1ycI/AAAAAAAABhY/TVsY6ItbmxspsPf4fXb-SfvgZxaUFuDMACLcBGAs/s640/start-jbpm-org.png" width="640" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;&lt;a href="http://start.jbpm.org/"&gt;start.jbpm.org&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;b&gt;Business application&lt;/b&gt; can be defined as an automated solution, built with selected frameworks and capabilities that implements business functions and/or business problems. Capabilities can be (among others):&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;persistence&lt;/li&gt;&lt;li&gt;messaging&lt;/li&gt;&lt;li&gt;transactions&lt;/li&gt;&lt;li&gt;business processes,&amp;nbsp;&lt;/li&gt;&lt;li&gt;business rules&lt;/li&gt;&lt;li&gt;planning solutions&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;Capabilities essentially define the features that your business application will be equipped with. Available options are:&lt;/div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;&lt;b&gt;Business automation&lt;/b&gt; covers features for process management, case management, decision management and optimisation. These will be by default configured in the service project of your business application. Although you can turn them off via configuration.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Decision management&lt;/b&gt; covers mainly decision and rules related features (backed by Drools project)&lt;/li&gt;&lt;li&gt;&lt;b&gt;Business optimisation&lt;/b&gt; covers planning problems and solutions related features (backed by OptaPlanner project)&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;&lt;br /&gt;&lt;div class="paragraph"&gt;Business application is more of a logical grouping of individual services that represent certain business capabilities. Usually they are deployed separately and can also be versioned individually. Overall goal is that the complete business application will allow particular domain to achieve their business goals e.g. order management, accommodation management, etc.&lt;br /&gt;&lt;br /&gt;Business application consists of various project types&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;&lt;b&gt;data model&lt;/b&gt; - basic maven/jar project to keep the data structures&lt;/li&gt;&lt;li&gt;&lt;b&gt;business assets&lt;/b&gt; - kjar project that can be easily imported into workbench for development&lt;/li&gt;&lt;li&gt;&lt;b&gt;service&lt;/b&gt; - service project that will include chosen capabilities with all bits configured&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="paragraph"&gt;Read more about business applications &lt;a href="https://docs.jboss.org/jbpm/release/7.12.0.Final/jbpm-docs/html_single/index.html#_overview_2"&gt;here&lt;/a&gt;&lt;/div&gt;&lt;div class="paragraph"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div class="paragraph"&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2 style="text-align: center;"&gt;Get started now!&lt;/h2&gt;&lt;div&gt;To get started with your first business application, just go to &lt;a href="http://start.jbpm.org/"&gt;start.jbpm.org&lt;/a&gt; and generate your business application. This will provide you with a zip file that will consists of (selected) projects ready to run.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Once you have the application up and running have a look at documentation that provides detailed description about business applications and various options in terms of configuration and development.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Make sure to not miss the tutorials that are included in the official documentation... these are being constantly updated so more and more guides are on the way. Each release will introduce at least 2 new tutorials ... so stay tuned.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2 style="text-align: center;"&gt;Samples and more&lt;/h2&gt;&lt;table align="center" cellpadding="0" cellspacing="0" class="tr-caption-container" style="margin-left: auto; margin-right: auto; text-align: center;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://4.bp.blogspot.com/-pwbl5zmVIbo/W8RSJTuw5BI/AAAAAAAABhg/cGzA7KUX3bgHeCI-kq99-Hm5wsXvQTJcACLcBGAs/s1600/Screen%2BShot%2B2018-10-15%2Bat%2B10.36.14.png" imageanchor="1" style="margin-left: auto; margin-right: auto;"&gt;&lt;img border="0" data-original-height="857" data-original-width="1073" height="510" src="https://4.bp.blogspot.com/-pwbl5zmVIbo/W8RSJTuw5BI/AAAAAAAABhg/cGzA7KUX3bgHeCI-kq99-Hm5wsXvQTJcACLcBGAs/s640/Screen%2BShot%2B2018-10-15%2Bat%2B10.36.14.png" width="640" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="text-align: center;"&gt;&lt;a href="https://github.com/business-applications"&gt;business-applications samples&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;div&gt;Business application launch cannot be done without quite few examples that can give you some ideas on how to get going, to name just few (and again more are coming)&lt;/div&gt;&lt;div&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;Driver pickup with IFTTT&amp;nbsp;&lt;/li&gt;&lt;li&gt;Dashboard app with Thymeleaf&lt;/li&gt;&lt;li&gt;IT Orders with tracking service built with Vert.x&lt;/li&gt;&lt;li&gt;Riot League of Legends&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;This &lt;a href="https://github.com/business-applications"&gt;business application GitHub organisation&lt;/a&gt; includes also source code for tutorials so make sure you visit it (and stay around for a bit as more will come).&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h2 style="text-align: center;"&gt;Call for contribution and feedback&lt;/h2&gt;&lt;div&gt;Last but not least, we would like to call out for contribution and feedback. Please give this approach a go and let us know what you think, what we could improve or share the ideas for business application you might have.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;Reach out to us&amp;nbsp;&lt;a href="https://jbpm.org/community/getHelp.html"&gt;via standard channels&lt;/a&gt; such as mailing lists or IRC channel.&lt;/div&gt;&lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/FkBeYf4Z7NA" height="1" width="1" alt=""/&gt;</content><summary>The time has come - Business Applications are here!!! It's a great pleasure to announce that the Business Applications are now officially launched and ready for you to get started. start.jbpm.org Business application can be defined as an automated solution, built with selected frameworks and capabilities that implements business functions and/or business problems. Capabilities can be (among others...</summary><dc:creator>Maciej Swiderski</dc:creator><dc:date>2018-10-15T08:55:00Z</dc:date><feedburner:origLink>http://mswiderski.blogspot.com/2018/10/launch-of-business-applications.html</feedburner:origLink></entry><entry><title>Hibernate Community Newsletter 20/2018</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/YvbAF6bWDNU/" /><category term="Discussions" scheme="searchisko:content:tags" /><category term="feed_group_name_hibernate" scheme="searchisko:content:tags" /><category term="feed_name_inrelationto" scheme="searchisko:content:tags" /><category term="Hibernate ORM" scheme="searchisko:content:tags" /><category term="newsletter" scheme="searchisko:content:tags" /><author><name>Vlad Mihalcea</name></author><id>searchisko:content:id:jbossorg_blog-hibernate_community_newsletter_20_2018</id><updated>2018-10-17T10:20:24Z</updated><published>2018-10-15T00:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Welcome to the Hibernate community newsletter in which we share blog posts, forum, and StackOverflow questions that are especially relevant to our users.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="books"&gt;&lt;a class="anchor" href="#books"&gt;&lt;/a&gt;Books&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;This &lt;a href="https://dzone.com/articles/5-books-to-learn-hibernate-for-java-developers"&gt;DZone article&lt;/a&gt; shows you the best 5 books to learn Hibernate.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="articles"&gt;&lt;a class="anchor" href="#articles"&gt;&lt;/a&gt;Articles&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In &lt;a href="https://medium.com/@jerolba/persisting-fast-in-database-1af4a281e3a"&gt;this article&lt;/a&gt;, Jerónimo López explains several optimizations that you do to speed up batch processing tasks when using JPA and Hibernate.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;When it comes to reading data, you should always fetch just as much data that you need to fulfill a given business requirement. Fetching more data than necessary is the most common problem that leads to application performance issues. For this reason, JPA and Hibernate provide &lt;a href="https://vladmihalcea.com/query-pagination-jpa-hibernate/"&gt;a very flexible query pagination mechanism&lt;/a&gt; that works for both entity queries (JPQL and Criteria API) and native SQL queries.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Using DTO projections is a very efficient way of fetching read-only data. If you are using Spring Data JPA, &lt;a href="https://www.bluemagma.be/2018/10/content-negotiation-with-spring-data-jpa-projections/"&gt;this article&lt;/a&gt; explains how to use content negotiation for specifying the DTO type.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;For our Portuguese readers, &lt;a href="http://db4beginners.com/blog/db-relacional-transacao/"&gt;this article&lt;/a&gt; explains what database transactions are and why you need them to ensure data integrity.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;In &lt;a href="https://www.theserverside.com/tip/How-JPA-and-Hibernate-simplify-data-persistence"&gt;this article&lt;/a&gt;, you are going to find how you can simplify data persistence with JPA and Hibernate.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Eugen Paraschiv wrote &lt;a href="https://www.baeldung.com/hibernate-proxy-load-method"&gt;an article&lt;/a&gt; about Hibernate proxies and how the &lt;code&gt;Session&lt;/code&gt; &lt;code&gt;load&lt;/code&gt; method works in comparison to the &lt;code&gt;get&lt;/code&gt; or &lt;code&gt;find&lt;/code&gt; methods.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="questions-and-answers"&gt;&lt;a class="anchor" href="#questions-and-answers"&gt;&lt;/a&gt;Questions and answers&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/52680020/hibernate-not-able-to-register-limit-function-of-mysql-in-custom-dialect/52701546#52701546"&gt;Hibernate not able to register 'LIMIT' function of MySQL in custom dialect&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/should-i-use-an-application-generated-entity-identifier-or-use-the-database-native-generator-with-hibernate/1493"&gt;Should I use an application-generated entity identifier or use the database native generator with Hibernate?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/19649194/hibernate-pagination-mechanism"&gt;Hibernate pagination mechanism&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/16088949/jpa-query-to-select-based-on-criteria-alongwith-pagination/52724851#52724851"&gt;How to paginate a JPA Query&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/42173894/hibernate-enablefilter-not-working-when-loading-entity-by-id/42197922#42197922"&gt;Hibernate enableFilter not working when loading entity by id&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/15974474/mapping-postgresql-json-column-to-hibernate-value-type/37946530#37946530"&gt;Mapping PostgreSQL JSON column to Hibernate value type&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/24877814/unidirectional-onetomany-fails-equality-test-in-jpa-2-1/24879391#24879391"&gt;Unidirectional @OneToMany association fails equality test in JPA&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/29869934/unit-testing-after-adding-database-with-hibernate/29877389#29877389"&gt;Unit testing after adding the database schema with Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/24901118/transactionmanager-for-multiple-databases/24901564#24901564"&gt;TransactionManager for multiple databases&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/30576385/how-to-log-the-start-and-the-completion-of-db-transactions-in-hibernate/30589533#30589533"&gt;How to log the start and the completion of DB transactions in Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/52678532/update-timestamp-for-each-row-in-hibernate/52732874#52732874"&gt;Update timestamp for each row in Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://stackoverflow.com/questions/29762653/why-does-hibernate-generate-a-cross-join-for-an-implicit-join-of-a-manytoone-as/29764340#29764340"&gt;Why does Hibernate generate a CROSS JOIN for an implicit join of a @ManyToOne association?&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/how-to-access-entity-properties-through-non-standard-getters-and-setters-with-hibernate/1513"&gt;How to access entity properties through non-standard getters and setters with Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/jpa-many-to-many-association-with-extra-columns-not-working-with-hibernate/1517"&gt;JPA many-to-many association with extra columns not working with Hibernate&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://discourse.hibernate.org/t/hibernate-5-3-sql-server-varchar-max-text-displayed-as-chinese-characters/1524/2"&gt;Hibernate 5.3, SQL Server varchar(max) text displayed as Chinese characters&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/YvbAF6bWDNU" height="1" width="1" alt=""/&gt;</content><summary>Welcome to the Hibernate community newsletter in which we share blog posts, forum, and StackOverflow questions that are especially relevant to our users. Books This DZone article shows you the best 5 books to learn Hibernate. Articles In this article, Jerónimo López explains several optimizations that you do to speed up batch processing tasks when using JPA and Hibernate. When it comes to reading ...</summary><dc:creator>Vlad Mihalcea</dc:creator><dc:date>2018-10-15T00:00:00Z</dc:date><feedburner:origLink>http://in.relation.to/2018/10/15/hibernate-community-newsletter-2018-20/</feedburner:origLink></entry><entry><title>Introducing Camel K</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/nHh3RLV1rOg/" /><category term="apache camel" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_nicolaferraro" scheme="searchisko:content:tags" /><category term="JBoss Fuse" scheme="searchisko:content:tags" /><category term="Knative" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="serverless" scheme="searchisko:content:tags" /><author><name>Nicola Ferraro</name></author><id>searchisko:content:id:jbossorg_blog-introducing_camel_k</id><updated>2018-10-15T13:00:00Z</updated><published>2018-10-14T22:00:00Z</published><content type="html">&lt;p&gt;Just few months ago, we were discussing about a new project that we could start as part of Apache Camel. A project with the potential to change the way people deal with integration. That project is now here and it’s called &lt;strong&gt;“Apache Camel K”&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;The “K” in the title is an obvious reference to &lt;a href="https://kubernetes.io/"&gt;&lt;strong&gt;Kubernetes&lt;/strong&gt;&lt;/a&gt;, you may think. But there’s also a less-obvious reference to &lt;a href="https://cloud.google.com/knative/"&gt;&lt;strong&gt;Knative&lt;/strong&gt;&lt;/a&gt;: a community project with the target of creating a common set of building blocks for &lt;strong&gt;serverless&lt;/strong&gt; applications. Yes, going “serverless” is the base idea that inspired many architectural decisions for Camel K.&lt;/p&gt; &lt;p&gt;But, let’s take this one step at time…&lt;/p&gt; &lt;h2 id="what-is-camel-k"&gt;What is “Camel K”?&lt;/h2&gt; &lt;p&gt;Apache Camel K is a lightweight cloud integration platform based on the Apache Camel framework. It &lt;strong&gt;runs natively on Kubernetes and Openshift&lt;/strong&gt; and it’s specifically designed for &lt;strong&gt;serverless and microservice architectures&lt;/strong&gt;. When I say “it runs”, I mean “it runs, now, you can try it!”. Just visit the homepage of the project on Github and follow the instructions: &lt;a href="https://github.com/apache/camel-k"&gt;&lt;strong&gt;https://github.com/apache/camel-k&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;It’s based on the “operator pattern” and leverages the &lt;a href="https://github.com/operator-framework/operator-sdk"&gt;Operator SDK&lt;/a&gt; to perform operations on Kubernetes resources (we define some &lt;a href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"&gt;custom resources&lt;/a&gt; beside the standard ones). The operator is written in &lt;a href="https://golang.org/"&gt;Go&lt;/a&gt; while the runtime is JVM based and leverages &lt;strong&gt;all the 200+ components&lt;/strong&gt; already available in Apache Camel.&lt;/p&gt; &lt;p&gt;Like Kubernetes and OpenShift, also &lt;strong&gt;Knative&lt;/strong&gt; will be a target platform in the near future. Specifically, we’re following the development of &lt;a href="https://github.com/knative/eventing"&gt;Knative Eventing&lt;/a&gt; and &lt;a href="https://github.com/knative/serving"&gt;Knative Serving&lt;/a&gt; building blocks to provide a full support for them, once they reach an adequate level of maturity.&lt;/p&gt; &lt;p&gt;Camel K brings integration to the next level, but at the same time is a return back to the roots for the Camel project: the &lt;a href="https://www.enterpriseintegrationpatterns.com/patterns/messaging/"&gt;&lt;strong&gt;Enterprise Integration Patterns (EIP)&lt;/strong&gt;&lt;/a&gt;. Camel has been shaped around enterprise integration patterns since its inception and developers have created a DSL that often maps patterns in a 1:1 relationship.&lt;/p&gt; &lt;p&gt;I’m not exaggerating if I state that now: &lt;strong&gt;the Camel DSL is the language of EIP&lt;/strong&gt;. It’s (at least in my opinion) the language that expresses better most of the patterns that were present in the original &lt;a href="https://www.enterpriseintegrationpatterns.com/index.html"&gt;“book of integration”&lt;/a&gt;, but also other patterns that have been added by the community during all these years. And the community keeps adding patterns and new components in every release.&lt;/p&gt; &lt;p&gt;The idea of Camel K is simply stated: &lt;strong&gt;let people use those Enterprise Integration Patterns natively on Kubernetes&lt;/strong&gt;, expressing them using the &lt;strong&gt;poweful Camel DSL&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;If I should provide a &lt;strong&gt;architectural overview&lt;/strong&gt; on Camel K, I’d draw the following diagrams:&lt;/p&gt; &lt;p style="text-align: center"&gt; &lt;img src="/images/post-camel-k-architecture.png" alt="Deployment Models for Camel K" /&gt; &lt;/p&gt; &lt;p&gt;Camel K is what you get if you take the &lt;strong&gt;integration DSL distilled&lt;/strong&gt; from the rest of the framework and offer a way to write integration code that is executed directly on a cloud platform: it may be a &lt;strong&gt;“modern” cloud&lt;/strong&gt; platform like Kubernetes or Openshift, or a &lt;strong&gt;“futuristic” cloud&lt;/strong&gt; platform like Knative for serverless workloads (Knative can run on both OpenShift and Kubernetes and it’s powered by &lt;a href="https://istio.io/"&gt;Istio&lt;/a&gt;).&lt;/p&gt; &lt;h2 id="how-does-it-work"&gt;How does it work?&lt;/h2&gt; &lt;p&gt;Speaking technically, the starting point is writing the integration code that we want to run. For example:&lt;/p&gt; &lt;p&gt;File: &lt;em&gt;integrate.groovy&lt;/em&gt;&lt;/p&gt; &lt;div class="language-groovy highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="c1"&gt;// expose a rest endpoint that routes messages to a Kafka topic&lt;/span&gt; &lt;span class="n"&gt;rest&lt;/span&gt;&lt;span class="o"&gt;().&lt;/span&gt;&lt;span class="na"&gt;post&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"/resources"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;route&lt;/span&gt;&lt;span class="o"&gt;()&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;to&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"kafka:messages"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;// transform all messages and publish them on a HTTP endpoint&lt;/span&gt; &lt;span class="n"&gt;from&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"kafka:messages"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;transform&lt;/span&gt;&lt;span class="o"&gt;()...&lt;/span&gt; &lt;span class="c1"&gt;// any kind of transformation&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;to&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"http://myendpoint/messages"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;Integrations can range from simple &lt;a href="https://github.com/apache/camel-k/blob/35aa1b3d39508ea901be7a7a1c5f4d256ce0eabb/runtime/examples/routes.js#L29"&gt;timer-to-log&lt;/a&gt; dummy examples to complex processing workflows connecting several external systems, but you write them using the same Camel DSL.&lt;/p&gt; &lt;p&gt;Actually, I talked about “a” Camel DSL, but many of you already know that the Camel DSL is not a proper standalone language, but a set of primitives that can be used in &lt;strong&gt;multiple programming languages&lt;/strong&gt;. So far we support the following languages:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Groovy&lt;/strong&gt;: it is probably the best language for scripting and it is currently the preferred language for writing Camel K integration code&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Kotlin&lt;/strong&gt;: yes, we support also Kotlin that offers a similar experience to Groovy&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Java&lt;/strong&gt;: it’s the classic Camel DSL that many of you already know&lt;/li&gt; &lt;li&gt;&lt;strong&gt;XML&lt;/strong&gt;: it’s also a classic DSL adaptation and give its best when you plan to use one of the visual editing tools that already exist&lt;/li&gt; &lt;li&gt;&lt;strong&gt;JavaScript&lt;/strong&gt;: yes, we support it as well!&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Let’s not complicate things too much and consider one of the simplest integration for the moment. The classic &lt;strong&gt;“Camel Hello World”&lt;/strong&gt;:&lt;/p&gt; &lt;p&gt;File: &lt;em&gt;hello.groovy&lt;/em&gt;&lt;/p&gt; &lt;div class="language-groovy highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;&lt;span class="n"&gt;from&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"timer:tick?period=3s"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;setBody&lt;/span&gt;&lt;span class="o"&gt;().&lt;/span&gt;&lt;span class="na"&gt;constant&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"Hello World from Camel K!!!"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;to&lt;/span&gt;&lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;"log:message"&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;A user that wants to run this integration on a cloud platform needs to download a small binary file that is available in the &lt;a href="https://github.com/apache/camel-k/releases"&gt;release page on the Camel K Github repository&lt;/a&gt;. It’s called &lt;strong&gt;kamel&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;The &lt;strong&gt;kamel&lt;/strong&gt; binary contains also a command to prepare your Kubernetes cluster for running integrations. Just run:&lt;/p&gt; &lt;div class="highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;kamel install &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;Will take care of installing the Camel K CRDs, setting up privileges and create the operator (see next) in the current namespace.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; in some cluster configurations, you need to be a cluster admin to install a CRD (it’s a operation that should be done only once for the entire cluster). The &lt;code class="highlighter-rouge"&gt;kamel&lt;/code&gt; binary will help you troubleshoot. If you want to work on a development cluster like &lt;em&gt;Minishift&lt;/em&gt; or &lt;em&gt;Minikube&lt;/em&gt;, you can easily follow the &lt;a href="https://github.com/apache/camel-k/blob/master/docs/cluster-setup.adoc"&gt;dev cluster setup guide&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Once the cluster is prepared and the operator installed in the current namespace:&lt;/p&gt; &lt;div class="highlighter-rouge"&gt;&lt;div class="highlight"&gt;&lt;pre class="highlight"&gt;&lt;code&gt;kamel run hello.groovy &lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt; &lt;p&gt;And your done!&lt;/p&gt; &lt;p&gt;This is what happens under the hood:&lt;/p&gt; &lt;p style="text-align: center"&gt; &lt;img src="/images/post-camel-k-architecture-detail.png" alt="Camel K Architecture Details" /&gt; &lt;/p&gt; &lt;p&gt;The &lt;strong&gt;kamel&lt;/strong&gt; tool will sync your code with a Kubernetes custom resource of Kind &lt;strong&gt;Integration&lt;/strong&gt; named &lt;strong&gt;hello&lt;/strong&gt; (after the file name) in the current namespace.&lt;/p&gt; &lt;p&gt;The &lt;strong&gt;Camel K Operator&lt;/strong&gt; is the component that makes all this possible by configuring all Kubernetes resources needed for running your integration. I’ll talk more about it later.&lt;/p&gt; &lt;p&gt;There exists also a &lt;strong&gt;dev mode&lt;/strong&gt; that allow users to create integration incrementally and with &lt;strong&gt;immediate “buildless” redeploys&lt;/strong&gt;. I think a demo is worth 1000 words.&lt;/p&gt; &lt;h2 id="demo"&gt;Demo&lt;/h2&gt; &lt;p&gt;The following video shows an example of what you can do with Camel K. It starts &lt;strong&gt;from the installation&lt;/strong&gt; on a Minishift dev cluster, showing how to run a basic quickstart. Then it proceeds with a &lt;strong&gt;more complex example&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;The second integration shown in the video will connect a &lt;strong&gt;Telegram&lt;/strong&gt; bot (you can interact with it through the Telegram app on your mobile phone) to a &lt;strong&gt;Kafka&lt;/strong&gt; topic that will be used to buffer messages and to throttle them. Messages will be received from Kafka again, filtered through one of the basic &lt;strong&gt;enterprise integration patterns&lt;/strong&gt; available out-of-the box in Apache Camel, then &lt;strong&gt;forwarded to a external HTTPS&lt;/strong&gt; endpoint.&lt;/p&gt; &lt;p&gt;All this is done in few minutes of video, and all integrations are created &lt;strong&gt;incrementally&lt;/strong&gt;, leveraging the new build engine behind Camel K that requires &lt;strong&gt;just 1 second to redeploy&lt;/strong&gt; the integration after each change.&lt;/p&gt; &lt;p&gt;Take a look:&lt;/p&gt; &lt;iframe width="560" height="315" src="https://www.youtube.com/embed/9Y5JfYiiBwM" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen=""&gt;&lt;/iframe&gt; &lt;h2 id="bringing-operators-to-the-next-level"&gt;Bringing “operators” to the next level&lt;/h2&gt; &lt;p&gt;&lt;a href="https://github.com/operator-framework/operator-sdk"&gt;Operator SDK&lt;/a&gt; is the framework that makes it possible to create all Kubernetes resources needed for running the “Camel DSL script”.&lt;/p&gt; &lt;p&gt;Operators are commonly used to install and configure applications or platforms on Kubernetes and Openshift. They are the digital version of the “human operator” that once installed the application in legacy environments, making sure that everything is in place for the application to run.&lt;/p&gt; &lt;p&gt;We brought this concept to the &lt;strong&gt;next level&lt;/strong&gt; in Camel K. The operator is &lt;strong&gt;“intelligent”&lt;/strong&gt; and knows what you want to run. It &lt;strong&gt;can understand the Camel DSL&lt;/strong&gt;.&lt;/p&gt; &lt;p&gt;So, &lt;strong&gt;for example&lt;/strong&gt;, if you define a REST endpoint using the Camel REST DSL, the operator will make sure that your integration is exposed to the outside and it will create a Service and a Route on OpenShift to expose it, or a Ingress on vanilla Kubernetes.&lt;/p&gt; &lt;p&gt;And in the future, it will have more administrative responsibilities:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;It will expose webhooks on Kubernetes and activate the webhook registration with the external provider to receive data&lt;/li&gt; &lt;li&gt;It will subscribe to feeds that you need to manage in your integration&lt;/li&gt; &lt;li&gt;It will convert your “polling” routes into Kubernetes Cronjobs for optimizing resource utilization&lt;/li&gt; &lt;li&gt;It will use a optimized Camel runtime platform under the hood if your routes support it&lt;/li&gt; &lt;li&gt;It will… do a lot of useful things!&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The operator will make sure that all you should do is writing your integration in a “Camel DSL Script”, without caring about any administrative operation. That’s what we mean with &lt;strong&gt;“intelligent operator”&lt;/strong&gt;.&lt;/p&gt; &lt;h2 id="whats-next"&gt;What’s next&lt;/h2&gt; &lt;p&gt;There are a lot of things coming. We keep updated the &lt;a href="https://github.com/apache/camel-k/projects"&gt;projects section&lt;/a&gt; in the github repository with the current areas we’re working on. Those include the already mentioned work on &lt;strong&gt;Knative&lt;/strong&gt; and also a &lt;strong&gt;Web UI&lt;/strong&gt; for Camel K that will really rock!&lt;/p&gt; &lt;p&gt;We love contributions! If you’re interested in the project, there are a lot of ways to contribute.&lt;/p&gt; &lt;p&gt;Meet us in our &lt;a href="https://gitter.im/apache/camel-k?utm_source=share-link&amp;amp;utm_medium=link&amp;amp;utm_campaign=share-link"&gt;dedicated Gitter room&lt;/a&gt; for more information.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/nHh3RLV1rOg" height="1" width="1" alt=""/&gt;</content><summary>Just few months ago, we were discussing about a new project that we could start as part of Apache Camel. A project with the potential to change the way people deal with integration. That project is now here and it’s called “Apache Camel K”. The “K” in the title is an obvious reference to Kubernetes, you may think. But there’s also a less-obvious reference to Knative: a community project with the t...</summary><dc:creator>Nicola Ferraro</dc:creator><dc:date>2018-10-14T22:00:00Z</dc:date><feedburner:origLink>https://www.nicolaferraro.me/2018/10/15/introducing-camel-k/</feedburner:origLink></entry></feed>
